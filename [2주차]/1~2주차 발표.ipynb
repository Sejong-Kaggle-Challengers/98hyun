{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:black;color:white;text-align:center;padding:20px\">병원 개/폐업 분류 예측 경진대회 리뷰</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>발표 순서</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    <ol>\n",
    "        <li>데이터 리뷰</li><br>\n",
    "        <li>전처리 리뷰</li><br>\n",
    "        <li>모델 리뷰</li><br>\n",
    "        <li>그 외</li>\n",
    "    </ol>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>데이터 리뷰</h3>\n",
    "\n",
    "먼저 train,test 데이터의 개수는 각각 (301, 58), (127, 58)로 이루어져 있다. <mark>매우 적다.  </mark>\n",
    "\n",
    "그 와중에 결측값과 숫자가 아닌 문자열이 섞여서 전처리해야 될때도 있었고, 그랬다.    \n",
    "\n",
    "코드공유를 봤는데 <mark>대부분 결측치를 채웠다.   </mark>\n",
    "\n",
    "숫자는 999 혹은 -1, -1은 employee 같은 경우였던거 같다. 문자는 'not_sure' 같은 문자로.  \n",
    "\n",
    "우선 나는 데이터를 지웠다. 그런데 이게 되게 안좋은거라고 했다.  \n",
    "\n",
    "원래 데이터가 적으면 과적합, 혹은 과소적합이 일어난다고 공부했었는데 이런 데이터가 작은 데이터셋은 버리는게 아까운거 같아서 그러는거같다.  \n",
    "\n",
    "중요한 데이터가 있을지도 모르고. 그래서 버리기보다 채웠던 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>전처리 리뷰</h3>  \n",
    "\n",
    "크게 결측값, 표준화, 범주의 숫자화, 파생변수에 대해 말하겠다.   \n",
    "\n",
    "결측값은 위에 설명한것에 이어진다. 데이터를 채울때 fillna(-999) 혹은 .loc 으로 직접 'notsure'을 넣었따.   \n",
    "\n",
    "눈에 들어올 skill 이나 다른건 없다.   \n",
    "\n",
    "<h4>표준화.</h4>\n",
    "\n",
    "일단 1,2,3등 모두 표준화 안했다. 난 <mark>당연히 하는건줄 알았는데 아니다. </mark>\n",
    "\n",
    "일단 표준화, 정규화를 하는 이유는   \n",
    "\n",
    "* scale 을 사용하는 이유 : 모델에도 계수가 있다고 한다. 특성마다 가질 수 있는 값의 스케일이 크게 차이가 나면 문제가 생기기도 한다. 정형화(regulation)는 과학습(overfitting)이 발생하는 것을 방지하기 위한 장치다. 과학습이 발생하면 특정 입력값에 대한 머신러닝 모델의 계수가 커진다. 하지만 입력값의 열마다 가질 수 있는 값의 범위에 크게 차이가 생기면 과학습의 발생 여부와 상관없이 각 입력값에 모델 계수 스케일도 크게 차이가 생겨서 정형화가 정상적으로 작동하지 않는다.  - 데이터 전처리 대전(책)\n",
    "\n",
    "* scale 을 사용하는 이유2 : 위의 이유말고도 정보를 이해하는데 유리할수도 불리할수도 있다고 한다. <a href=\"https://m.blog.naver.com/PostView.nhn?blogId=jhkim6363&logNo=221135574314&proxyReferer=https:%2F%2Fwww.google.com%2F\">참고 - ctrl + f 로 '상대적인 중요성' 검색하면 더 빨리 찾을 수 있다. </a>\n",
    "\n",
    "내가 느낀 표준화나 정규화는 <mark>파생변수로써의 역할</mark>이라는 것이다. 이번엔 그렇게 안했지만, 다음엔 그렇게 할 것이다. <a href=\"https://www.kaggle.com/tmheo74/kakr-4-3rd-place-solution\">참고 - ctrl+f 로 'log1p' 검색.</a>\n",
    "\n",
    "\n",
    "<h4>범주의 숫자화</h4>\n",
    "\n",
    "이번 범주 중 어떻게 처리해야할지 헷갈린게 sido 와 owner change다. 이번에 공부한 내용이다.  \n",
    "\n",
    "2. one-hot encoding vs label encoding  -> 웬만하면 label encoding 과 frequency encoding\n",
    "    * label 인코딩은 rank 를 생각하고 한게 아닌데도 숫자개념때문에 순서가 생긴다. \n",
    "        * 순서가 있을때 하면 좋다. \n",
    "        * 내용이 많이 있을때 하면 좋다. \n",
    "    * one hot 인코딩은 더미 트랩을 일으켜 다중공선성(독립 특성간 종속성)이 발생한다.\n",
    "        * 순서가 없을때 \n",
    "        * 내용이 많이 없을때 하면 좋다.  \n",
    "        \n",
    "회귀엔 원핫인코딩이 좋고, 트리에는 label인코딩이 좋다고 한다. 어디서 봤는진 까먹었다.   \n",
    "\n",
    "각각 단점과 장점이 있다.   \n",
    "\n",
    "위 같은 전처리가 필요한 이유는 모델이 이해하기 위해서이다. <mark>모델은 숫자밖에 이해를 못한다. </mark>\n",
    "\n",
    "<h4>파생변수</h4>\n",
    "\n",
    "1,3등은 파생변수를 사용했고, 2등은 안했다.   \n",
    "\n",
    "변수=특성이다. 특성이 생기면 더 오래걸리고 혹은 필요없을 수도 있고 한데, 이번 파생변수를 어떻게 해야할지 처음엔 생각을 안해봤다.  \n",
    "\n",
    "1등 같은 경우는 순이익/순매출 지표를 시도했다.    \n",
    "\n",
    "이번에 재무 관련 특성에 대해서 어느정도 알아야 했다.   \n",
    "\n",
    "이런 정보를 알아가는게 <mark>도메인지식</mark>이라고 했다. 도메인 지식을 얻기 위해서는 끊임없이 찾아봐야한다고 한다. 답이 없다.  \n",
    "\n",
    "그리고 통계지식도 알아야한다. 적절히 사용 될 때가 있다는 것이다. <a href=\"https://dacon.io/codeshare/1457?dtype=recent\">참고 - ctrl + f 로 '기하 평균' 혹은 '산술 평균' 검색. </a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 리뷰</h3>\n",
    "\n",
    "최종적으로 사용한 모델은 xgboost 와 randomforest, catboost 다.   \n",
    "\n",
    "일단, 1등은 모델이라고 하기 뭐한. 모델 하나로 몇몇 특성들을 예측한 값을 누적했고,   \n",
    "\n",
    "2등은 앙상블을 통한 배깅.  \n",
    "\n",
    "3등은 xgboost 을 사용했다.  \n",
    "\n",
    "1. 보팅,배깅,부스팅 차이   \n",
    "    1-1. 보팅 : 소프트 ( 확률 평균 ) ,하드 ( 최빈값 )  \n",
    "    1-2. 배깅 : 여러개로 나눠서 학습한것을 다수결로  \n",
    "    1-3. 부스팅 : 여러개의 분류기의 가중 학습을 거쳐 결정된다.      \n",
    "    이 모든 것을 아우르는 앙상블.\n",
    "    \n",
    "결국, 서로 다른 예측을 하는 모델을 합치는것이 좋은 예측을 하는것이다.  \n",
    "\n",
    "위 3개의 모델 선택의 이유는 1번 단일 모델들의 앙상블을 통한 예측, 2번 모든 모델들의 예측값 배깅 3번 그 중 random forest와 catboost 가 다른 모델들과 합치면 좋다고 한다. k-nn 모델들이 좋다고 한다. 어떻게든 계속 합치거나 혹은 잘 선택하거나가 중요하다고 한다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>그 외</h3>\n",
    "\n",
    "구글 코랩이 생각보다 사용이 간편하고, 좋더라.catboost 돌릴때 안돌아갔는데 colab으로 돌렸다.  \n",
    "\n",
    "영어로 검색하는게 얻을때가 많더라. 예를 들어, xgboost 의 파라미터를 검색하고 싶으면 xgboost parameter in python 이런식으로 치면 된다.  \n",
    "\n",
    "in 이 생각보다 잘나온다. 위 예는 document를 찾아도 금방 찾는데 만약 더 어려운게 있다 싶으면   \n",
    "\n",
    "google에 몇번 검색해보고 안나오면   \n",
    "\n",
    "```\n",
    "1번 kaggle \n",
    "matplotlib 시각화 어떻게 하는지모를때 kaggle 가서 matplotlib tutorial 하면 document 보다 잘 알려준다.  \n",
    "다른것을 검색해도 된다.  \n",
    "\n",
    "2번 stackoverflow.com \n",
    "구글 검색할때 site:stackoverflow.com 하면 편하다.  \n",
    "\n",
    "다른 검색할때도 유용하더라.  \n",
    "\n",
    "3번 github\n",
    "\n",
    "github도 좋다.  \n",
    "```\n",
    "<a href=\"https://ahrefs.com/blog/google-advanced-search-operators/\">참고</a>\n",
    "\n",
    "이번 책에서 하나 봤는데 employee1 처음에 문자열 추출이 안되서 loc으로 하나씩하나씩 했는데  \n",
    "\n",
    "read_csv(thousands=',') 파라미터를 주면 되더라.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
