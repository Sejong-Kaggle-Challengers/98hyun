{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/../input/tabular-playground-series-mar-2021/train.csv')\ntest=pd.read_csv('/kaggle/input/../input/tabular-playground-series-mar-2021/test.csv')\nsubmit=pd.read_csv('/kaggle/input/../input/tabular-playground-series-mar-2021/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def datainfo(df):\n    return pd.DataFrame([(col,df[col].nunique(),df[col].dtype,df[col].isna().sum(),\n                         df[col].unique()[:5]) for col in df.columns],\n                        columns=['name','nunique','dtype','missing','value:5'])\ndatainfo(train)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"      name  nunique    dtype  missing  \\\n0       id   300000    int64        0   \n1     cat0        2   object        0   \n2     cat1       15   object        0   \n3     cat2       19   object        0   \n4     cat3       13   object        0   \n5     cat4       20   object        0   \n6     cat5       84   object        0   \n7     cat6       16   object        0   \n8     cat7       51   object        0   \n9     cat8       61   object        0   \n10    cat9       19   object        0   \n11   cat10      299   object        0   \n12   cat11        2   object        0   \n13   cat12        2   object        0   \n14   cat13        2   object        0   \n15   cat14        2   object        0   \n16   cat15        4   object        0   \n17   cat16        4   object        0   \n18   cat17        4   object        0   \n19   cat18        4   object        0   \n20   cont0   299874  float64        0   \n21   cont1   299861  float64        0   \n22   cont2   299872  float64        0   \n23   cont3   299818  float64        0   \n24   cont4   299876  float64        0   \n25   cont5   299791  float64        0   \n26   cont6   299843  float64        0   \n27   cont7   299880  float64        0   \n28   cont8   299849  float64        0   \n29   cont9   299859  float64        0   \n30  cont10   299823  float64        0   \n31  target        2    int64        0   \n\n                                              value:5  \n0                                     [0, 1, 2, 3, 4]  \n1                                              [A, B]  \n2                                     [I, K, A, F, L]  \n3                                     [A, G, C, O, D]  \n4                                     [B, A, C, D, G]  \n5                                     [B, E, H, I, D]  \n6                                  [BI, AB, BU, M, T]  \n7                                     [A, K, C, I, G]  \n8                                     [S, W, E, Y, G]  \n9                                  [Q, AD, BM, Y, AG]  \n10                                    [A, F, L, C, E]  \n11                               [LO, HJ, DJ, KV, DP]  \n12                                             [A, B]  \n13                                             [A, B]  \n14                                             [A, B]  \n15                                             [A, B]  \n16                                       [B, D, A, C]  \n17                                       [D, B, C, A]  \n18                                       [D, C, B, A]  \n19                                       [B, C, D, A]  \n20  [0.6298580932886344, 0.3707271036893566, 0.502...  \n21  [0.8553490496453626, 0.3289294232850693, 0.322...  \n22  [0.7594386994154677, 0.3863848396544993, 0.343...  \n23  [0.795549256871245, 0.5413662314603979, 0.6163...  \n24  [0.6819172514031219, 0.3889824529295912, 0.793...  \n25  [0.6216718236057862, 0.3577782607273347, 0.552...  \n26  [0.5921843772206821, 0.6000435979273233, 0.352...  \n27  [0.7919207159113629, 0.4087010629559668, 0.388...  \n28  [0.8152537462248601, 0.3993525724989473, 0.412...  \n29  [0.965006328742958, 0.9274058250023683, 0.2926...  \n30  [0.6659151198639575, 0.4937292188969079, 0.549...  \n31                                             [0, 1]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>nunique</th>\n      <th>dtype</th>\n      <th>missing</th>\n      <th>value:5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>300000</td>\n      <td>int64</td>\n      <td>0</td>\n      <td>[0, 1, 2, 3, 4]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cat0</td>\n      <td>2</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, B]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat1</td>\n      <td>15</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[I, K, A, F, L]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat2</td>\n      <td>19</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, G, C, O, D]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cat3</td>\n      <td>13</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[B, A, C, D, G]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cat4</td>\n      <td>20</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[B, E, H, I, D]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>cat5</td>\n      <td>84</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[BI, AB, BU, M, T]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cat6</td>\n      <td>16</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, K, C, I, G]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>cat7</td>\n      <td>51</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[S, W, E, Y, G]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cat8</td>\n      <td>61</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[Q, AD, BM, Y, AG]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>cat9</td>\n      <td>19</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, F, L, C, E]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>cat10</td>\n      <td>299</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[LO, HJ, DJ, KV, DP]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cat11</td>\n      <td>2</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, B]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cat12</td>\n      <td>2</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, B]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>cat13</td>\n      <td>2</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, B]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>cat14</td>\n      <td>2</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[A, B]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>cat15</td>\n      <td>4</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[B, D, A, C]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>cat16</td>\n      <td>4</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[D, B, C, A]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>cat17</td>\n      <td>4</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[D, C, B, A]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>cat18</td>\n      <td>4</td>\n      <td>object</td>\n      <td>0</td>\n      <td>[B, C, D, A]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>cont0</td>\n      <td>299874</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.6298580932886344, 0.3707271036893566, 0.502...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>cont1</td>\n      <td>299861</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.8553490496453626, 0.3289294232850693, 0.322...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>cont2</td>\n      <td>299872</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.7594386994154677, 0.3863848396544993, 0.343...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>cont3</td>\n      <td>299818</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.795549256871245, 0.5413662314603979, 0.6163...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>cont4</td>\n      <td>299876</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.6819172514031219, 0.3889824529295912, 0.793...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>cont5</td>\n      <td>299791</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.6216718236057862, 0.3577782607273347, 0.552...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>cont6</td>\n      <td>299843</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.5921843772206821, 0.6000435979273233, 0.352...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>cont7</td>\n      <td>299880</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.7919207159113629, 0.4087010629559668, 0.388...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>cont8</td>\n      <td>299849</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.8152537462248601, 0.3993525724989473, 0.412...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>cont9</td>\n      <td>299859</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.965006328742958, 0.9274058250023683, 0.2926...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>cont10</td>\n      <td>299823</td>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.6659151198639575, 0.4937292188969079, 0.549...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>target</td>\n      <td>2</td>\n      <td>int64</td>\n      <td>0</td>\n      <td>[0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols=[col for col in train.columns if 'cat' in col]\nnum_cols=[col for col in train.columns if 'cont' in col]\ntarget=train['target']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from category_encoders import LeaveOneOutEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\nxgb_cat_features = []\nlgb_cat_features = []\ncb_cat_features = []\nknn_cat_features= []\n\nloo_features = []\nle_features = []\n\n# label encoding은 x에 잘 안쓰는데 쓰는 경우도 있다. \n# 그리고 train과 test 모두를 아우르는 fit을 사용한다. \n# train만 fit 하고 transform을 train,test하는 줄 알았는데 이러면 data leakage가 있을것같다. \n# 하지만, train에서만 fitting 이되고 test에 안되면 overfitting이니까 필요한것 같기도 하고. \n\ndef label_encode(train_df, test_df, column):\n    le = LabelEncoder()\n    new_feature = \"{}_le\".format(column)\n    le.fit(train_df[column].unique().tolist() + test_df[column].unique().tolist())\n    train_df[new_feature] = le.transform(train_df[column])\n    test_df[new_feature] = le.transform(test_df[column])\n    return new_feature\n\n# leave-ont-out encoding은 train으로만 fit. \n\ndef loo_encode(train_df, test_df, column):\n    loo = LeaveOneOutEncoder()\n    new_feature = \"{}_loo\".format(column)\n    loo.fit(train_df[column], train_df[\"target\"])\n    train_df[new_feature] = loo.transform(train_df[column])\n    test_df[new_feature] = loo.transform(test_df[column])\n    return new_feature\n\nfor feature in cat_cols:\n    loo_features.append(loo_encode(train, test, feature))\n    le_features.append(label_encode(train, test, feature))\n    \nxgb_cat_features.extend(loo_features)\n# lightgbm 은 label encoding 이 잘 먹히나보다.\nlgb_cat_features.extend(le_features)\n# catboost 는 category 분석 모델이라 그런지 그대로 넣는다.\ncb_cat_features.extend(cat_cols)\nknn_cat_features.extend(loo_features)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate Level 1 Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nrandom_state = 2021\nn_folds = 5\nk_fold = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n\nxgb_train_preds = np.zeros(len(train.index), )\nxgb_test_preds = np.zeros(len(test.index), )\nxgb_features = xgb_cat_features + num_cols\n\nlgb_train_preds = np.zeros(len(train.index), )\nlgb_test_preds = np.zeros(len(test.index), )\nlgb_features = lgb_cat_features + num_cols\n\ncb_train_preds = np.zeros(len(train.index), )\ncb_test_preds = np.zeros(len(test.index), )\ncb_features = cb_cat_features + num_cols\n\nknn_train_preds = np.zeros(len(train.index), )\nknn_test_preds = np.zeros(len(test.index), )\nknn_features = knn_cat_features + num_cols\n\nfor fold, (train_index, test_index) in enumerate(k_fold.split(train, target)):\n    print(\"--> Fold {}\".format(fold + 1))\n    y_train = target.iloc[train_index]\n    y_valid = target.iloc[test_index]\n\n    xgb_x_train = pd.DataFrame(train[xgb_features].iloc[train_index])\n    xgb_x_valid = pd.DataFrame(train[xgb_features].iloc[test_index])\n\n    lgb_x_train = pd.DataFrame(train[lgb_features].iloc[train_index])\n    lgb_x_valid = pd.DataFrame(train[lgb_features].iloc[test_index])\n\n    cb_x_train = pd.DataFrame(train[cb_features].iloc[train_index])\n    cb_x_valid = pd.DataFrame(train[cb_features].iloc[test_index])\n\n    knn_x_train = pd.DataFrame(train[knn_features].iloc[train_index])\n    knn_x_valid = pd.DataFrame(train[knn_features].iloc[test_index])\n\n    xgb_model = XGBClassifier(\n        seed=random_state,\n        eval_metric=\"auc\"\n    )\n    xgb_model.fit(\n        xgb_x_train,\n        y_train,\n        eval_set=[(xgb_x_valid, y_valid)], \n    )\n\n    train_oof_preds = xgb_model.predict_proba(xgb_x_valid)[:,1]\n    test_oof_preds = xgb_model.predict_proba(test[xgb_features])[:,1]\n    xgb_train_preds[test_index] = train_oof_preds\n    xgb_test_preds += test_oof_preds / n_folds\n    print(\": XGB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n\n    lgb_model = LGBMClassifier(\n        # 번호로 접근 하는것 같다. 그래서 처음에 cat_features들을 앞에 넣었다. \n        cat_feature=[x for x in range(len(lgb_cat_features))],\n        random_state=random_state,\n        metric=\"auc\"\n    )\n    lgb_model.fit(\n        lgb_x_train,\n        y_train,\n        eval_set=[(lgb_x_valid, y_valid)], \n    )\n\n    train_oof_preds = lgb_model.predict_proba(lgb_x_valid)[:,1]\n    test_oof_preds = lgb_model.predict_proba(test[lgb_features])[:,1]\n    lgb_train_preds[test_index] = train_oof_preds\n    lgb_test_preds += test_oof_preds / n_folds\n    print(\": LGB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n\n    cb_model = CatBoostClassifier(\n        eval_metric=\"AUC\",\n        loss_function=\"Logloss\",\n        random_state=random_state,\n        cat_features=[x for x in range(len(cb_cat_features))]\n    )\n    cb_model.fit(\n        cb_x_train,\n        y_train,\n        eval_set=[(cb_x_valid, y_valid)], \n        verbose=0,\n    )\n\n    train_oof_preds = cb_model.predict_proba(cb_x_valid)[:,1]\n    test_oof_preds = cb_model.predict_proba(test[cb_features])[:,1]\n    cb_train_preds[test_index] = train_oof_preds\n    cb_test_preds += test_oof_preds / n_folds\n    print(\": CB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n    \n    knn_model = KNeighborsClassifier()\n    knn_model.fit(\n        knn_x_train,\n        y_train,\n    )\n\n    train_oof_preds = knn_model.predict_proba(knn_x_valid)[:,-1]\n    test_oof_preds = knn_model.predict_proba(test[knn_features])[:,-1]\n    knn_train_preds[test_index] = train_oof_preds\n    knn_test_preds += test_oof_preds / n_folds\n    print(\": KNN - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n    \nprint(\"--> Overall metrics\")\nprint(\": XGB - ROC AUC Score = {}\".format(roc_auc_score(target, xgb_train_preds, average=\"micro\")))\nprint(\": LGB - ROC AUC Score = {}\".format(roc_auc_score(target, lgb_train_preds, average=\"micro\")))\nprint(\": CB - ROC AUC Score = {}\".format(roc_auc_score(target, cb_train_preds, average=\"micro\")))\nprint(\": KNN - ROC AUC Score = {}\".format(roc_auc_score(target, knn_train_preds, average=\"micro\")))","execution_count":15,"outputs":[{"output_type":"stream","text":"--> Fold 1\n[0]\tvalidation_0-auc:0.85994\n[1]\tvalidation_0-auc:0.86685\n[2]\tvalidation_0-auc:0.86939\n[3]\tvalidation_0-auc:0.87389\n[4]\tvalidation_0-auc:0.87557\n[5]\tvalidation_0-auc:0.87715\n[6]\tvalidation_0-auc:0.87831\n[7]\tvalidation_0-auc:0.87946\n[8]\tvalidation_0-auc:0.88057\n[9]\tvalidation_0-auc:0.88145\n[10]\tvalidation_0-auc:0.88246\n[11]\tvalidation_0-auc:0.88333\n[12]\tvalidation_0-auc:0.88394\n[13]\tvalidation_0-auc:0.88432\n[14]\tvalidation_0-auc:0.88511\n[15]\tvalidation_0-auc:0.88531\n[16]\tvalidation_0-auc:0.88573\n[17]\tvalidation_0-auc:0.88586\n[18]\tvalidation_0-auc:0.88613\n[19]\tvalidation_0-auc:0.88648\n[20]\tvalidation_0-auc:0.88696\n[21]\tvalidation_0-auc:0.88715\n[22]\tvalidation_0-auc:0.88755\n[23]\tvalidation_0-auc:0.88784\n[24]\tvalidation_0-auc:0.88795\n[25]\tvalidation_0-auc:0.88804\n[26]\tvalidation_0-auc:0.88815\n[27]\tvalidation_0-auc:0.88830\n[28]\tvalidation_0-auc:0.88854\n[29]\tvalidation_0-auc:0.88859\n[30]\tvalidation_0-auc:0.88866\n[31]\tvalidation_0-auc:0.88875\n[32]\tvalidation_0-auc:0.88884\n[33]\tvalidation_0-auc:0.88889\n[34]\tvalidation_0-auc:0.88898\n[35]\tvalidation_0-auc:0.88902\n[36]\tvalidation_0-auc:0.88910\n[37]\tvalidation_0-auc:0.88910\n[38]\tvalidation_0-auc:0.88912\n[39]\tvalidation_0-auc:0.88913\n[40]\tvalidation_0-auc:0.88933\n[41]\tvalidation_0-auc:0.88937\n[42]\tvalidation_0-auc:0.88939\n[43]\tvalidation_0-auc:0.88939\n[44]\tvalidation_0-auc:0.88948\n[45]\tvalidation_0-auc:0.88958\n[46]\tvalidation_0-auc:0.88970\n[47]\tvalidation_0-auc:0.88968\n[48]\tvalidation_0-auc:0.88960\n[49]\tvalidation_0-auc:0.88963\n[50]\tvalidation_0-auc:0.88965\n[51]\tvalidation_0-auc:0.88964\n[52]\tvalidation_0-auc:0.88962\n[53]\tvalidation_0-auc:0.88965\n[54]\tvalidation_0-auc:0.88972\n[55]\tvalidation_0-auc:0.88977\n[56]\tvalidation_0-auc:0.88978\n[57]\tvalidation_0-auc:0.88987\n[58]\tvalidation_0-auc:0.89000\n[59]\tvalidation_0-auc:0.88998\n[60]\tvalidation_0-auc:0.89001\n[61]\tvalidation_0-auc:0.89002\n[62]\tvalidation_0-auc:0.89005\n[63]\tvalidation_0-auc:0.89018\n[64]\tvalidation_0-auc:0.89016\n[65]\tvalidation_0-auc:0.89042\n[66]\tvalidation_0-auc:0.89048\n[67]\tvalidation_0-auc:0.89051\n[68]\tvalidation_0-auc:0.89046\n[69]\tvalidation_0-auc:0.89038\n[70]\tvalidation_0-auc:0.89040\n[71]\tvalidation_0-auc:0.89045\n[72]\tvalidation_0-auc:0.89041\n[73]\tvalidation_0-auc:0.89041\n[74]\tvalidation_0-auc:0.89037\n[75]\tvalidation_0-auc:0.89035\n[76]\tvalidation_0-auc:0.89032\n[77]\tvalidation_0-auc:0.89035\n[78]\tvalidation_0-auc:0.89037\n[79]\tvalidation_0-auc:0.89038\n[80]\tvalidation_0-auc:0.89036\n[81]\tvalidation_0-auc:0.89034\n[82]\tvalidation_0-auc:0.89031\n[83]\tvalidation_0-auc:0.89029\n[84]\tvalidation_0-auc:0.89039\n[85]\tvalidation_0-auc:0.89043\n[86]\tvalidation_0-auc:0.89041\n[87]\tvalidation_0-auc:0.89042\n[88]\tvalidation_0-auc:0.89044\n[89]\tvalidation_0-auc:0.89043\n[90]\tvalidation_0-auc:0.89051\n[91]\tvalidation_0-auc:0.89054\n[92]\tvalidation_0-auc:0.89056\n[93]\tvalidation_0-auc:0.89057\n[94]\tvalidation_0-auc:0.89055\n[95]\tvalidation_0-auc:0.89057\n[96]\tvalidation_0-auc:0.89051\n[97]\tvalidation_0-auc:0.89052\n[98]\tvalidation_0-auc:0.89049\n[99]\tvalidation_0-auc:0.89044\n: XGB - ROC AUC Score = 0.8904401706965017\n[1]\tvalid_0's auc: 0.853131\n[2]\tvalid_0's auc: 0.85897\n[3]\tvalid_0's auc: 0.86095\n[4]\tvalid_0's auc: 0.86413\n[5]\tvalid_0's auc: 0.866462\n[6]\tvalid_0's auc: 0.868695\n[7]\tvalid_0's auc: 0.871692\n[8]\tvalid_0's auc: 0.873538\n[9]\tvalid_0's auc: 0.874559\n[10]\tvalid_0's auc: 0.875309\n[11]\tvalid_0's auc: 0.876267\n[12]\tvalid_0's auc: 0.876948\n[13]\tvalid_0's auc: 0.877471\n[14]\tvalid_0's auc: 0.878174\n[15]\tvalid_0's auc: 0.878877\n[16]\tvalid_0's auc: 0.879391\n[17]\tvalid_0's auc: 0.879755\n[18]\tvalid_0's auc: 0.880366\n[19]\tvalid_0's auc: 0.88086\n[20]\tvalid_0's auc: 0.881256\n[21]\tvalid_0's auc: 0.881713\n[22]\tvalid_0's auc: 0.88225\n[23]\tvalid_0's auc: 0.882772\n[24]\tvalid_0's auc: 0.883294\n[25]\tvalid_0's auc: 0.883691\n[26]\tvalid_0's auc: 0.884052\n[27]\tvalid_0's auc: 0.884464\n[28]\tvalid_0's auc: 0.884786\n[29]\tvalid_0's auc: 0.885156\n[30]\tvalid_0's auc: 0.885549\n[31]\tvalid_0's auc: 0.88572\n[32]\tvalid_0's auc: 0.88608\n[33]\tvalid_0's auc: 0.88639\n[34]\tvalid_0's auc: 0.886687\n[35]\tvalid_0's auc: 0.886924\n[36]\tvalid_0's auc: 0.887205\n[37]\tvalid_0's auc: 0.887476\n[38]\tvalid_0's auc: 0.887714\n[39]\tvalid_0's auc: 0.887946\n[40]\tvalid_0's auc: 0.888131\n[41]\tvalid_0's auc: 0.888374\n[42]\tvalid_0's auc: 0.888482\n[43]\tvalid_0's auc: 0.88869\n[44]\tvalid_0's auc: 0.888912\n[45]\tvalid_0's auc: 0.889103\n[46]\tvalid_0's auc: 0.889297\n[47]\tvalid_0's auc: 0.889395\n[48]\tvalid_0's auc: 0.889573\n[49]\tvalid_0's auc: 0.889671\n[50]\tvalid_0's auc: 0.889871\n[51]\tvalid_0's auc: 0.889973\n[52]\tvalid_0's auc: 0.890122\n[53]\tvalid_0's auc: 0.890219\n[54]\tvalid_0's auc: 0.890346\n[55]\tvalid_0's auc: 0.890473\n[56]\tvalid_0's auc: 0.890603\n[57]\tvalid_0's auc: 0.89068\n[58]\tvalid_0's auc: 0.890775\n[59]\tvalid_0's auc: 0.890875\n[60]\tvalid_0's auc: 0.890962\n[61]\tvalid_0's auc: 0.891066\n[62]\tvalid_0's auc: 0.891165\n[63]\tvalid_0's auc: 0.891208\n[64]\tvalid_0's auc: 0.891265\n[65]\tvalid_0's auc: 0.891337\n[66]\tvalid_0's auc: 0.891436\n[67]\tvalid_0's auc: 0.891491\n[68]\tvalid_0's auc: 0.891554\n[69]\tvalid_0's auc: 0.891605\n[70]\tvalid_0's auc: 0.891639\n[71]\tvalid_0's auc: 0.891693\n[72]\tvalid_0's auc: 0.891747\n[73]\tvalid_0's auc: 0.891821\n[74]\tvalid_0's auc: 0.891873\n[75]\tvalid_0's auc: 0.891936\n[76]\tvalid_0's auc: 0.892002\n[77]\tvalid_0's auc: 0.892041\n[78]\tvalid_0's auc: 0.892063\n[79]\tvalid_0's auc: 0.892095\n[80]\tvalid_0's auc: 0.892137\n[81]\tvalid_0's auc: 0.892152\n[82]\tvalid_0's auc: 0.892149\n[83]\tvalid_0's auc: 0.892203\n[84]\tvalid_0's auc: 0.892222\n[85]\tvalid_0's auc: 0.892271\n[86]\tvalid_0's auc: 0.892309\n[87]\tvalid_0's auc: 0.892355\n[88]\tvalid_0's auc: 0.892379\n[89]\tvalid_0's auc: 0.89237\n[90]\tvalid_0's auc: 0.892371\n[91]\tvalid_0's auc: 0.892427\n[92]\tvalid_0's auc: 0.892478\n[93]\tvalid_0's auc: 0.892514\n[94]\tvalid_0's auc: 0.892558\n[95]\tvalid_0's auc: 0.892601\n[96]\tvalid_0's auc: 0.892618\n[97]\tvalid_0's auc: 0.892664\n[98]\tvalid_0's auc: 0.892702\n[99]\tvalid_0's auc: 0.89271\n[100]\tvalid_0's auc: 0.892777\n: LGB - ROC AUC Score = 0.8927770335237142\n: CB - ROC AUC Score = 0.8952732097343109\n: KNN - ROC AUC Score = 0.8357353953882185\n--> Fold 2\n[0]\tvalidation_0-auc:0.85589\n[1]\tvalidation_0-auc:0.86317\n[2]\tvalidation_0-auc:0.86669\n[3]\tvalidation_0-auc:0.87052\n[4]\tvalidation_0-auc:0.87247\n[5]\tvalidation_0-auc:0.87488\n[6]\tvalidation_0-auc:0.87564\n[7]\tvalidation_0-auc:0.87680\n[8]\tvalidation_0-auc:0.87765\n[9]\tvalidation_0-auc:0.87844\n[10]\tvalidation_0-auc:0.87952\n[11]\tvalidation_0-auc:0.88033\n[12]\tvalidation_0-auc:0.88081\n[13]\tvalidation_0-auc:0.88127\n[14]\tvalidation_0-auc:0.88185\n[15]\tvalidation_0-auc:0.88199\n[16]\tvalidation_0-auc:0.88257\n[17]\tvalidation_0-auc:0.88331\n[18]\tvalidation_0-auc:0.88360\n[19]\tvalidation_0-auc:0.88391\n[20]\tvalidation_0-auc:0.88415\n[21]\tvalidation_0-auc:0.88448\n[22]\tvalidation_0-auc:0.88454\n[23]\tvalidation_0-auc:0.88465\n[24]\tvalidation_0-auc:0.88492\n[25]\tvalidation_0-auc:0.88508\n[26]\tvalidation_0-auc:0.88530\n[27]\tvalidation_0-auc:0.88529\n[28]\tvalidation_0-auc:0.88550\n[29]\tvalidation_0-auc:0.88574\n[30]\tvalidation_0-auc:0.88581\n[31]\tvalidation_0-auc:0.88590\n[32]\tvalidation_0-auc:0.88604\n[33]\tvalidation_0-auc:0.88611\n[34]\tvalidation_0-auc:0.88623\n[35]\tvalidation_0-auc:0.88630\n[36]\tvalidation_0-auc:0.88641\n[37]\tvalidation_0-auc:0.88646\n[38]\tvalidation_0-auc:0.88657\n[39]\tvalidation_0-auc:0.88674\n[40]\tvalidation_0-auc:0.88686\n[41]\tvalidation_0-auc:0.88696\n[42]\tvalidation_0-auc:0.88704\n[43]\tvalidation_0-auc:0.88701\n[44]\tvalidation_0-auc:0.88700\n[45]\tvalidation_0-auc:0.88701\n[46]\tvalidation_0-auc:0.88699\n[47]\tvalidation_0-auc:0.88705\n[48]\tvalidation_0-auc:0.88711\n[49]\tvalidation_0-auc:0.88719\n[50]\tvalidation_0-auc:0.88721\n[51]\tvalidation_0-auc:0.88731\n[52]\tvalidation_0-auc:0.88746\n[53]\tvalidation_0-auc:0.88747\n[54]\tvalidation_0-auc:0.88749\n[55]\tvalidation_0-auc:0.88753\n[56]\tvalidation_0-auc:0.88752\n[57]\tvalidation_0-auc:0.88752\n[58]\tvalidation_0-auc:0.88759\n[59]\tvalidation_0-auc:0.88756\n[60]\tvalidation_0-auc:0.88763\n[61]\tvalidation_0-auc:0.88772\n[62]\tvalidation_0-auc:0.88767\n[63]\tvalidation_0-auc:0.88767\n[64]\tvalidation_0-auc:0.88770\n[65]\tvalidation_0-auc:0.88766\n[66]\tvalidation_0-auc:0.88771\n[67]\tvalidation_0-auc:0.88774\n[68]\tvalidation_0-auc:0.88776\n[69]\tvalidation_0-auc:0.88775\n[70]\tvalidation_0-auc:0.88775\n[71]\tvalidation_0-auc:0.88783\n","name":"stdout"},{"output_type":"stream","text":"[72]\tvalidation_0-auc:0.88777\n[73]\tvalidation_0-auc:0.88779\n[74]\tvalidation_0-auc:0.88776\n[75]\tvalidation_0-auc:0.88777\n[76]\tvalidation_0-auc:0.88775\n[77]\tvalidation_0-auc:0.88775\n[78]\tvalidation_0-auc:0.88774\n[79]\tvalidation_0-auc:0.88775\n[80]\tvalidation_0-auc:0.88771\n[81]\tvalidation_0-auc:0.88766\n[82]\tvalidation_0-auc:0.88765\n[83]\tvalidation_0-auc:0.88766\n[84]\tvalidation_0-auc:0.88770\n[85]\tvalidation_0-auc:0.88766\n[86]\tvalidation_0-auc:0.88765\n[87]\tvalidation_0-auc:0.88762\n[88]\tvalidation_0-auc:0.88763\n[89]\tvalidation_0-auc:0.88765\n[90]\tvalidation_0-auc:0.88765\n[91]\tvalidation_0-auc:0.88760\n[92]\tvalidation_0-auc:0.88763\n[93]\tvalidation_0-auc:0.88764\n[94]\tvalidation_0-auc:0.88764\n[95]\tvalidation_0-auc:0.88775\n[96]\tvalidation_0-auc:0.88774\n[97]\tvalidation_0-auc:0.88774\n[98]\tvalidation_0-auc:0.88771\n[99]\tvalidation_0-auc:0.88774\n: XGB - ROC AUC Score = 0.8877365552589255\n[1]\tvalid_0's auc: 0.850163\n[2]\tvalid_0's auc: 0.854319\n[3]\tvalid_0's auc: 0.857463\n[4]\tvalid_0's auc: 0.860013\n[5]\tvalid_0's auc: 0.861834\n[6]\tvalid_0's auc: 0.864087\n[7]\tvalid_0's auc: 0.865444\n[8]\tvalid_0's auc: 0.868025\n[9]\tvalid_0's auc: 0.869456\n[10]\tvalid_0's auc: 0.870512\n[11]\tvalid_0's auc: 0.871034\n[12]\tvalid_0's auc: 0.872061\n[13]\tvalid_0's auc: 0.87295\n[14]\tvalid_0's auc: 0.873533\n[15]\tvalid_0's auc: 0.87441\n[16]\tvalid_0's auc: 0.874844\n[17]\tvalid_0's auc: 0.875534\n[18]\tvalid_0's auc: 0.876216\n[19]\tvalid_0's auc: 0.876767\n[20]\tvalid_0's auc: 0.877255\n[21]\tvalid_0's auc: 0.877741\n[22]\tvalid_0's auc: 0.878311\n[23]\tvalid_0's auc: 0.878865\n[24]\tvalid_0's auc: 0.879418\n[25]\tvalid_0's auc: 0.880022\n[26]\tvalid_0's auc: 0.880438\n[27]\tvalid_0's auc: 0.880784\n[28]\tvalid_0's auc: 0.881112\n[29]\tvalid_0's auc: 0.881406\n[30]\tvalid_0's auc: 0.881746\n[31]\tvalid_0's auc: 0.882134\n[32]\tvalid_0's auc: 0.882445\n[33]\tvalid_0's auc: 0.882715\n[34]\tvalid_0's auc: 0.883023\n[35]\tvalid_0's auc: 0.883305\n[36]\tvalid_0's auc: 0.883502\n[37]\tvalid_0's auc: 0.883735\n[38]\tvalid_0's auc: 0.884015\n[39]\tvalid_0's auc: 0.884247\n[40]\tvalid_0's auc: 0.884423\n[41]\tvalid_0's auc: 0.88457\n[42]\tvalid_0's auc: 0.884766\n[43]\tvalid_0's auc: 0.885016\n[44]\tvalid_0's auc: 0.88518\n[45]\tvalid_0's auc: 0.885436\n[46]\tvalid_0's auc: 0.885565\n[47]\tvalid_0's auc: 0.885733\n[48]\tvalid_0's auc: 0.885872\n[49]\tvalid_0's auc: 0.886034\n[50]\tvalid_0's auc: 0.886177\n[51]\tvalid_0's auc: 0.886297\n[52]\tvalid_0's auc: 0.886382\n[53]\tvalid_0's auc: 0.886487\n[54]\tvalid_0's auc: 0.886594\n[55]\tvalid_0's auc: 0.886667\n[56]\tvalid_0's auc: 0.886784\n[57]\tvalid_0's auc: 0.886886\n[58]\tvalid_0's auc: 0.886994\n[59]\tvalid_0's auc: 0.88705\n[60]\tvalid_0's auc: 0.887157\n[61]\tvalid_0's auc: 0.887279\n[62]\tvalid_0's auc: 0.887482\n[63]\tvalid_0's auc: 0.887558\n[64]\tvalid_0's auc: 0.887645\n[65]\tvalid_0's auc: 0.887745\n[66]\tvalid_0's auc: 0.887896\n[67]\tvalid_0's auc: 0.887938\n[68]\tvalid_0's auc: 0.888016\n[69]\tvalid_0's auc: 0.888095\n[70]\tvalid_0's auc: 0.888156\n[71]\tvalid_0's auc: 0.888236\n[72]\tvalid_0's auc: 0.888314\n[73]\tvalid_0's auc: 0.888361\n[74]\tvalid_0's auc: 0.888419\n[75]\tvalid_0's auc: 0.888508\n[76]\tvalid_0's auc: 0.888569\n[77]\tvalid_0's auc: 0.888686\n[78]\tvalid_0's auc: 0.888732\n[79]\tvalid_0's auc: 0.888773\n[80]\tvalid_0's auc: 0.888805\n[81]\tvalid_0's auc: 0.888804\n[82]\tvalid_0's auc: 0.888908\n[83]\tvalid_0's auc: 0.888948\n[84]\tvalid_0's auc: 0.88901\n[85]\tvalid_0's auc: 0.889047\n[86]\tvalid_0's auc: 0.889076\n[87]\tvalid_0's auc: 0.889162\n[88]\tvalid_0's auc: 0.889188\n[89]\tvalid_0's auc: 0.889207\n[90]\tvalid_0's auc: 0.889227\n[91]\tvalid_0's auc: 0.889254\n[92]\tvalid_0's auc: 0.889293\n[93]\tvalid_0's auc: 0.88932\n[94]\tvalid_0's auc: 0.889319\n[95]\tvalid_0's auc: 0.889356\n[96]\tvalid_0's auc: 0.889407\n[97]\tvalid_0's auc: 0.889434\n[98]\tvalid_0's auc: 0.889474\n[99]\tvalid_0's auc: 0.889492\n[100]\tvalid_0's auc: 0.889542\n: LGB - ROC AUC Score = 0.8895420879158679\n: CB - ROC AUC Score = 0.8926983611902333\n: KNN - ROC AUC Score = 0.8323276464096742\n--> Fold 3\n[0]\tvalidation_0-auc:0.86203\n[1]\tvalidation_0-auc:0.86881\n[2]\tvalidation_0-auc:0.87183\n[3]\tvalidation_0-auc:0.87531\n[4]\tvalidation_0-auc:0.87710\n[5]\tvalidation_0-auc:0.87857\n[6]\tvalidation_0-auc:0.87975\n[7]\tvalidation_0-auc:0.88057\n[8]\tvalidation_0-auc:0.88194\n[9]\tvalidation_0-auc:0.88290\n[10]\tvalidation_0-auc:0.88359\n[11]\tvalidation_0-auc:0.88438\n[12]\tvalidation_0-auc:0.88485\n[13]\tvalidation_0-auc:0.88517\n[14]\tvalidation_0-auc:0.88539\n[15]\tvalidation_0-auc:0.88575\n[16]\tvalidation_0-auc:0.88620\n[17]\tvalidation_0-auc:0.88665\n[18]\tvalidation_0-auc:0.88679\n[19]\tvalidation_0-auc:0.88697\n[20]\tvalidation_0-auc:0.88706\n[21]\tvalidation_0-auc:0.88737\n[22]\tvalidation_0-auc:0.88770\n[23]\tvalidation_0-auc:0.88773\n[24]\tvalidation_0-auc:0.88801\n[25]\tvalidation_0-auc:0.88821\n[26]\tvalidation_0-auc:0.88830\n[27]\tvalidation_0-auc:0.88830\n[28]\tvalidation_0-auc:0.88854\n[29]\tvalidation_0-auc:0.88867\n[30]\tvalidation_0-auc:0.88889\n[31]\tvalidation_0-auc:0.88889\n[32]\tvalidation_0-auc:0.88899\n[33]\tvalidation_0-auc:0.88918\n[34]\tvalidation_0-auc:0.88931\n[35]\tvalidation_0-auc:0.88934\n[36]\tvalidation_0-auc:0.88938\n[37]\tvalidation_0-auc:0.88949\n[38]\tvalidation_0-auc:0.88958\n[39]\tvalidation_0-auc:0.88965\n[40]\tvalidation_0-auc:0.88962\n[41]\tvalidation_0-auc:0.88965\n[42]\tvalidation_0-auc:0.88971\n[43]\tvalidation_0-auc:0.88975\n[44]\tvalidation_0-auc:0.88980\n[45]\tvalidation_0-auc:0.88980\n[46]\tvalidation_0-auc:0.88981\n[47]\tvalidation_0-auc:0.88974\n[48]\tvalidation_0-auc:0.88980\n[49]\tvalidation_0-auc:0.88969\n[50]\tvalidation_0-auc:0.88970\n[51]\tvalidation_0-auc:0.88972\n[52]\tvalidation_0-auc:0.88974\n[53]\tvalidation_0-auc:0.88976\n[54]\tvalidation_0-auc:0.88997\n[55]\tvalidation_0-auc:0.88999\n[56]\tvalidation_0-auc:0.88993\n[57]\tvalidation_0-auc:0.88998\n[58]\tvalidation_0-auc:0.88996\n[59]\tvalidation_0-auc:0.89004\n[60]\tvalidation_0-auc:0.88998\n[61]\tvalidation_0-auc:0.89010\n[62]\tvalidation_0-auc:0.89006\n[63]\tvalidation_0-auc:0.89010\n[64]\tvalidation_0-auc:0.89015\n[65]\tvalidation_0-auc:0.89008\n[66]\tvalidation_0-auc:0.89008\n[67]\tvalidation_0-auc:0.89017\n[68]\tvalidation_0-auc:0.89014\n[69]\tvalidation_0-auc:0.89014\n[70]\tvalidation_0-auc:0.89011\n[71]\tvalidation_0-auc:0.89020\n[72]\tvalidation_0-auc:0.89018\n[73]\tvalidation_0-auc:0.89016\n[74]\tvalidation_0-auc:0.89015\n[75]\tvalidation_0-auc:0.89016\n[76]\tvalidation_0-auc:0.89019\n[77]\tvalidation_0-auc:0.89013\n[78]\tvalidation_0-auc:0.89024\n[79]\tvalidation_0-auc:0.89025\n[80]\tvalidation_0-auc:0.89024\n[81]\tvalidation_0-auc:0.89025\n[82]\tvalidation_0-auc:0.89027\n[83]\tvalidation_0-auc:0.89026\n[84]\tvalidation_0-auc:0.89023\n[85]\tvalidation_0-auc:0.89026\n[86]\tvalidation_0-auc:0.89027\n[87]\tvalidation_0-auc:0.89027\n[88]\tvalidation_0-auc:0.89025\n[89]\tvalidation_0-auc:0.89026\n[90]\tvalidation_0-auc:0.89027\n[91]\tvalidation_0-auc:0.89027\n[92]\tvalidation_0-auc:0.89025\n[93]\tvalidation_0-auc:0.89025\n[94]\tvalidation_0-auc:0.89027\n[95]\tvalidation_0-auc:0.89026\n[96]\tvalidation_0-auc:0.89023\n[97]\tvalidation_0-auc:0.89015\n[98]\tvalidation_0-auc:0.89014\n[99]\tvalidation_0-auc:0.89012\n: XGB - ROC AUC Score = 0.8901230518523842\n[1]\tvalid_0's auc: 0.857123\n[2]\tvalid_0's auc: 0.860842\n[3]\tvalid_0's auc: 0.865635\n[4]\tvalid_0's auc: 0.867931\n[5]\tvalid_0's auc: 0.868836\n[6]\tvalid_0's auc: 0.870877\n[7]\tvalid_0's auc: 0.873278\n[8]\tvalid_0's auc: 0.874232\n[9]\tvalid_0's auc: 0.875323\n[10]\tvalid_0's auc: 0.875831\n[11]\tvalid_0's auc: 0.876808\n[12]\tvalid_0's auc: 0.877455\n[13]\tvalid_0's auc: 0.878305\n[14]\tvalid_0's auc: 0.878732\n[15]\tvalid_0's auc: 0.879401\n[16]\tvalid_0's auc: 0.879995\n[17]\tvalid_0's auc: 0.880642\n[18]\tvalid_0's auc: 0.881141\n[19]\tvalid_0's auc: 0.881689\n[20]\tvalid_0's auc: 0.882101\n[21]\tvalid_0's auc: 0.882527\n[22]\tvalid_0's auc: 0.882987\n[23]\tvalid_0's auc: 0.883506\n[24]\tvalid_0's auc: 0.88387\n[25]\tvalid_0's auc: 0.884152\n[26]\tvalid_0's auc: 0.884629\n[27]\tvalid_0's auc: 0.884972\n[28]\tvalid_0's auc: 0.885262\n[29]\tvalid_0's auc: 0.885593\n[30]\tvalid_0's auc: 0.88583\n[31]\tvalid_0's auc: 0.886021\n[32]\tvalid_0's auc: 0.886329\n[33]\tvalid_0's auc: 0.88658\n[34]\tvalid_0's auc: 0.886821\n[35]\tvalid_0's auc: 0.887014\n[36]\tvalid_0's auc: 0.887223\n[37]\tvalid_0's auc: 0.887437\n[38]\tvalid_0's auc: 0.887686\n[39]\tvalid_0's auc: 0.887925\n[40]\tvalid_0's auc: 0.888101\n[41]\tvalid_0's auc: 0.888263\n[42]\tvalid_0's auc: 0.888369\n[43]\tvalid_0's auc: 0.888514\n[44]\tvalid_0's auc: 0.888729\n[45]\tvalid_0's auc: 0.888855\n[46]\tvalid_0's auc: 0.889029\n[47]\tvalid_0's auc: 0.889201\n[48]\tvalid_0's auc: 0.889347\n[49]\tvalid_0's auc: 0.889418\n","name":"stdout"},{"output_type":"stream","text":"[50]\tvalid_0's auc: 0.889527\n[51]\tvalid_0's auc: 0.889641\n[52]\tvalid_0's auc: 0.889701\n[53]\tvalid_0's auc: 0.889775\n[54]\tvalid_0's auc: 0.889955\n[55]\tvalid_0's auc: 0.890005\n[56]\tvalid_0's auc: 0.890095\n[57]\tvalid_0's auc: 0.890194\n[58]\tvalid_0's auc: 0.890266\n[59]\tvalid_0's auc: 0.890304\n[60]\tvalid_0's auc: 0.8904\n[61]\tvalid_0's auc: 0.890433\n[62]\tvalid_0's auc: 0.890506\n[63]\tvalid_0's auc: 0.890559\n[64]\tvalid_0's auc: 0.890622\n[65]\tvalid_0's auc: 0.890703\n[66]\tvalid_0's auc: 0.890739\n[67]\tvalid_0's auc: 0.890784\n[68]\tvalid_0's auc: 0.890822\n[69]\tvalid_0's auc: 0.890829\n[70]\tvalid_0's auc: 0.890901\n[71]\tvalid_0's auc: 0.890988\n[72]\tvalid_0's auc: 0.891026\n[73]\tvalid_0's auc: 0.891074\n[74]\tvalid_0's auc: 0.891108\n[75]\tvalid_0's auc: 0.891146\n[76]\tvalid_0's auc: 0.891178\n[77]\tvalid_0's auc: 0.891223\n[78]\tvalid_0's auc: 0.891255\n[79]\tvalid_0's auc: 0.89132\n[80]\tvalid_0's auc: 0.891401\n[81]\tvalid_0's auc: 0.891442\n[82]\tvalid_0's auc: 0.891447\n[83]\tvalid_0's auc: 0.891517\n[84]\tvalid_0's auc: 0.891578\n[85]\tvalid_0's auc: 0.891633\n[86]\tvalid_0's auc: 0.891684\n[87]\tvalid_0's auc: 0.891761\n[88]\tvalid_0's auc: 0.891791\n[89]\tvalid_0's auc: 0.891866\n[90]\tvalid_0's auc: 0.891879\n[91]\tvalid_0's auc: 0.891917\n[92]\tvalid_0's auc: 0.891969\n[93]\tvalid_0's auc: 0.891958\n[94]\tvalid_0's auc: 0.892001\n[95]\tvalid_0's auc: 0.89202\n[96]\tvalid_0's auc: 0.892057\n[97]\tvalid_0's auc: 0.892077\n[98]\tvalid_0's auc: 0.892101\n[99]\tvalid_0's auc: 0.89215\n[100]\tvalid_0's auc: 0.892189\n: LGB - ROC AUC Score = 0.8921887903295553\n: CB - ROC AUC Score = 0.8947337743014646\n: KNN - ROC AUC Score = 0.8357559470757439\n--> Fold 4\n[0]\tvalidation_0-auc:0.85994\n[1]\tvalidation_0-auc:0.86676\n[2]\tvalidation_0-auc:0.87041\n[3]\tvalidation_0-auc:0.87330\n[4]\tvalidation_0-auc:0.87547\n[5]\tvalidation_0-auc:0.87703\n[6]\tvalidation_0-auc:0.87882\n[7]\tvalidation_0-auc:0.87967\n[8]\tvalidation_0-auc:0.88060\n[9]\tvalidation_0-auc:0.88141\n[10]\tvalidation_0-auc:0.88254\n[11]\tvalidation_0-auc:0.88311\n[12]\tvalidation_0-auc:0.88373\n[13]\tvalidation_0-auc:0.88424\n[14]\tvalidation_0-auc:0.88476\n[15]\tvalidation_0-auc:0.88495\n[16]\tvalidation_0-auc:0.88518\n[17]\tvalidation_0-auc:0.88545\n[18]\tvalidation_0-auc:0.88605\n[19]\tvalidation_0-auc:0.88630\n[20]\tvalidation_0-auc:0.88682\n[21]\tvalidation_0-auc:0.88717\n[22]\tvalidation_0-auc:0.88755\n[23]\tvalidation_0-auc:0.88772\n[24]\tvalidation_0-auc:0.88792\n[25]\tvalidation_0-auc:0.88818\n[26]\tvalidation_0-auc:0.88846\n[27]\tvalidation_0-auc:0.88876\n[28]\tvalidation_0-auc:0.88885\n[29]\tvalidation_0-auc:0.88912\n[30]\tvalidation_0-auc:0.88938\n[31]\tvalidation_0-auc:0.88945\n[32]\tvalidation_0-auc:0.88948\n[33]\tvalidation_0-auc:0.88963\n[34]\tvalidation_0-auc:0.88968\n[35]\tvalidation_0-auc:0.88980\n[36]\tvalidation_0-auc:0.88982\n[37]\tvalidation_0-auc:0.88987\n[38]\tvalidation_0-auc:0.88994\n[39]\tvalidation_0-auc:0.88992\n[40]\tvalidation_0-auc:0.88994\n[41]\tvalidation_0-auc:0.88996\n[42]\tvalidation_0-auc:0.88990\n[43]\tvalidation_0-auc:0.89004\n[44]\tvalidation_0-auc:0.89008\n[45]\tvalidation_0-auc:0.89015\n[46]\tvalidation_0-auc:0.89017\n[47]\tvalidation_0-auc:0.89016\n[48]\tvalidation_0-auc:0.89028\n[49]\tvalidation_0-auc:0.89044\n[50]\tvalidation_0-auc:0.89048\n[51]\tvalidation_0-auc:0.89043\n[52]\tvalidation_0-auc:0.89046\n[53]\tvalidation_0-auc:0.89042\n[54]\tvalidation_0-auc:0.89045\n[55]\tvalidation_0-auc:0.89046\n[56]\tvalidation_0-auc:0.89048\n[57]\tvalidation_0-auc:0.89051\n[58]\tvalidation_0-auc:0.89058\n[59]\tvalidation_0-auc:0.89059\n[60]\tvalidation_0-auc:0.89060\n[61]\tvalidation_0-auc:0.89061\n[62]\tvalidation_0-auc:0.89064\n[63]\tvalidation_0-auc:0.89068\n[64]\tvalidation_0-auc:0.89072\n[65]\tvalidation_0-auc:0.89076\n[66]\tvalidation_0-auc:0.89074\n[67]\tvalidation_0-auc:0.89084\n[68]\tvalidation_0-auc:0.89077\n[69]\tvalidation_0-auc:0.89074\n[70]\tvalidation_0-auc:0.89076\n[71]\tvalidation_0-auc:0.89076\n[72]\tvalidation_0-auc:0.89076\n[73]\tvalidation_0-auc:0.89076\n[74]\tvalidation_0-auc:0.89074\n[75]\tvalidation_0-auc:0.89072\n[76]\tvalidation_0-auc:0.89070\n[77]\tvalidation_0-auc:0.89075\n[78]\tvalidation_0-auc:0.89075\n[79]\tvalidation_0-auc:0.89075\n[80]\tvalidation_0-auc:0.89078\n[81]\tvalidation_0-auc:0.89081\n[82]\tvalidation_0-auc:0.89081\n[83]\tvalidation_0-auc:0.89079\n[84]\tvalidation_0-auc:0.89077\n[85]\tvalidation_0-auc:0.89074\n[86]\tvalidation_0-auc:0.89075\n[87]\tvalidation_0-auc:0.89079\n[88]\tvalidation_0-auc:0.89078\n[89]\tvalidation_0-auc:0.89076\n[90]\tvalidation_0-auc:0.89076\n[91]\tvalidation_0-auc:0.89076\n[92]\tvalidation_0-auc:0.89079\n[93]\tvalidation_0-auc:0.89084\n[94]\tvalidation_0-auc:0.89091\n[95]\tvalidation_0-auc:0.89089\n[96]\tvalidation_0-auc:0.89088\n[97]\tvalidation_0-auc:0.89087\n[98]\tvalidation_0-auc:0.89087\n[99]\tvalidation_0-auc:0.89089\n: XGB - ROC AUC Score = 0.8908903005872755\n[1]\tvalid_0's auc: 0.854657\n[2]\tvalid_0's auc: 0.858415\n[3]\tvalid_0's auc: 0.861102\n[4]\tvalid_0's auc: 0.864536\n[5]\tvalid_0's auc: 0.866666\n[6]\tvalid_0's auc: 0.86829\n[7]\tvalid_0's auc: 0.869862\n[8]\tvalid_0's auc: 0.872061\n[9]\tvalid_0's auc: 0.873009\n[10]\tvalid_0's auc: 0.874377\n[11]\tvalid_0's auc: 0.875271\n[12]\tvalid_0's auc: 0.875879\n[13]\tvalid_0's auc: 0.876536\n[14]\tvalid_0's auc: 0.87699\n[15]\tvalid_0's auc: 0.877822\n[16]\tvalid_0's auc: 0.878405\n[17]\tvalid_0's auc: 0.879051\n[18]\tvalid_0's auc: 0.87968\n[19]\tvalid_0's auc: 0.880217\n[20]\tvalid_0's auc: 0.880703\n[21]\tvalid_0's auc: 0.880976\n[22]\tvalid_0's auc: 0.881512\n[23]\tvalid_0's auc: 0.882089\n[24]\tvalid_0's auc: 0.882711\n[25]\tvalid_0's auc: 0.883138\n[26]\tvalid_0's auc: 0.883643\n[27]\tvalid_0's auc: 0.88405\n[28]\tvalid_0's auc: 0.884465\n[29]\tvalid_0's auc: 0.884798\n[30]\tvalid_0's auc: 0.885159\n[31]\tvalid_0's auc: 0.885539\n[32]\tvalid_0's auc: 0.885847\n[33]\tvalid_0's auc: 0.886154\n[34]\tvalid_0's auc: 0.886433\n[35]\tvalid_0's auc: 0.88667\n[36]\tvalid_0's auc: 0.886888\n[37]\tvalid_0's auc: 0.887101\n[38]\tvalid_0's auc: 0.887287\n[39]\tvalid_0's auc: 0.887464\n[40]\tvalid_0's auc: 0.887704\n[41]\tvalid_0's auc: 0.887936\n[42]\tvalid_0's auc: 0.888094\n[43]\tvalid_0's auc: 0.888227\n[44]\tvalid_0's auc: 0.888374\n[45]\tvalid_0's auc: 0.888556\n[46]\tvalid_0's auc: 0.888656\n[47]\tvalid_0's auc: 0.888867\n[48]\tvalid_0's auc: 0.88908\n[49]\tvalid_0's auc: 0.889236\n[50]\tvalid_0's auc: 0.889314\n[51]\tvalid_0's auc: 0.889458\n[52]\tvalid_0's auc: 0.889568\n[53]\tvalid_0's auc: 0.889704\n[54]\tvalid_0's auc: 0.889879\n[55]\tvalid_0's auc: 0.889979\n[56]\tvalid_0's auc: 0.890102\n[57]\tvalid_0's auc: 0.890234\n[58]\tvalid_0's auc: 0.89034\n[59]\tvalid_0's auc: 0.890413\n[60]\tvalid_0's auc: 0.890479\n[61]\tvalid_0's auc: 0.890596\n[62]\tvalid_0's auc: 0.890691\n[63]\tvalid_0's auc: 0.890765\n[64]\tvalid_0's auc: 0.890823\n[65]\tvalid_0's auc: 0.890965\n[66]\tvalid_0's auc: 0.891106\n[67]\tvalid_0's auc: 0.891151\n[68]\tvalid_0's auc: 0.891207\n[69]\tvalid_0's auc: 0.891275\n[70]\tvalid_0's auc: 0.891311\n[71]\tvalid_0's auc: 0.891363\n[72]\tvalid_0's auc: 0.89143\n[73]\tvalid_0's auc: 0.891483\n[74]\tvalid_0's auc: 0.891532\n[75]\tvalid_0's auc: 0.891594\n[76]\tvalid_0's auc: 0.891634\n[77]\tvalid_0's auc: 0.891661\n[78]\tvalid_0's auc: 0.891744\n[79]\tvalid_0's auc: 0.891805\n[80]\tvalid_0's auc: 0.891856\n[81]\tvalid_0's auc: 0.891902\n[82]\tvalid_0's auc: 0.891943\n[83]\tvalid_0's auc: 0.891944\n[84]\tvalid_0's auc: 0.892023\n[85]\tvalid_0's auc: 0.892064\n[86]\tvalid_0's auc: 0.892105\n[87]\tvalid_0's auc: 0.892164\n[88]\tvalid_0's auc: 0.892188\n[89]\tvalid_0's auc: 0.892244\n[90]\tvalid_0's auc: 0.892262\n[91]\tvalid_0's auc: 0.892273\n[92]\tvalid_0's auc: 0.892309\n[93]\tvalid_0's auc: 0.892338\n[94]\tvalid_0's auc: 0.89235\n[95]\tvalid_0's auc: 0.892374\n[96]\tvalid_0's auc: 0.892393\n[97]\tvalid_0's auc: 0.892443\n[98]\tvalid_0's auc: 0.892462\n[99]\tvalid_0's auc: 0.892495\n[100]\tvalid_0's auc: 0.892545\n: LGB - ROC AUC Score = 0.892544789896415\n: CB - ROC AUC Score = 0.8965143142460817\n: KNN - ROC AUC Score = 0.8339922182574493\n--> Fold 5\n[0]\tvalidation_0-auc:0.85937\n[1]\tvalidation_0-auc:0.86611\n[2]\tvalidation_0-auc:0.86987\n[3]\tvalidation_0-auc:0.87269\n[4]\tvalidation_0-auc:0.87409\n[5]\tvalidation_0-auc:0.87554\n[6]\tvalidation_0-auc:0.87649\n[7]\tvalidation_0-auc:0.87729\n[8]\tvalidation_0-auc:0.87901\n[9]\tvalidation_0-auc:0.87985\n[10]\tvalidation_0-auc:0.88047\n[11]\tvalidation_0-auc:0.88104\n[12]\tvalidation_0-auc:0.88140\n[13]\tvalidation_0-auc:0.88186\n[14]\tvalidation_0-auc:0.88237\n[15]\tvalidation_0-auc:0.88283\n[16]\tvalidation_0-auc:0.88302\n[17]\tvalidation_0-auc:0.88338\n","name":"stdout"},{"output_type":"stream","text":"[18]\tvalidation_0-auc:0.88370\n[19]\tvalidation_0-auc:0.88386\n[20]\tvalidation_0-auc:0.88397\n[21]\tvalidation_0-auc:0.88427\n[22]\tvalidation_0-auc:0.88462\n[23]\tvalidation_0-auc:0.88502\n[24]\tvalidation_0-auc:0.88508\n[25]\tvalidation_0-auc:0.88529\n[26]\tvalidation_0-auc:0.88543\n[27]\tvalidation_0-auc:0.88547\n[28]\tvalidation_0-auc:0.88555\n[29]\tvalidation_0-auc:0.88565\n[30]\tvalidation_0-auc:0.88566\n[31]\tvalidation_0-auc:0.88577\n[32]\tvalidation_0-auc:0.88594\n[33]\tvalidation_0-auc:0.88602\n[34]\tvalidation_0-auc:0.88603\n[35]\tvalidation_0-auc:0.88630\n[36]\tvalidation_0-auc:0.88633\n[37]\tvalidation_0-auc:0.88644\n[38]\tvalidation_0-auc:0.88644\n[39]\tvalidation_0-auc:0.88645\n[40]\tvalidation_0-auc:0.88652\n[41]\tvalidation_0-auc:0.88672\n[42]\tvalidation_0-auc:0.88679\n[43]\tvalidation_0-auc:0.88677\n[44]\tvalidation_0-auc:0.88684\n[45]\tvalidation_0-auc:0.88685\n[46]\tvalidation_0-auc:0.88683\n[47]\tvalidation_0-auc:0.88686\n[48]\tvalidation_0-auc:0.88691\n[49]\tvalidation_0-auc:0.88691\n[50]\tvalidation_0-auc:0.88693\n[51]\tvalidation_0-auc:0.88696\n[52]\tvalidation_0-auc:0.88720\n[53]\tvalidation_0-auc:0.88721\n[54]\tvalidation_0-auc:0.88712\n[55]\tvalidation_0-auc:0.88727\n[56]\tvalidation_0-auc:0.88728\n[57]\tvalidation_0-auc:0.88740\n[58]\tvalidation_0-auc:0.88743\n[59]\tvalidation_0-auc:0.88743\n[60]\tvalidation_0-auc:0.88741\n[61]\tvalidation_0-auc:0.88741\n[62]\tvalidation_0-auc:0.88741\n[63]\tvalidation_0-auc:0.88733\n[64]\tvalidation_0-auc:0.88733\n[65]\tvalidation_0-auc:0.88735\n[66]\tvalidation_0-auc:0.88738\n[67]\tvalidation_0-auc:0.88744\n[68]\tvalidation_0-auc:0.88743\n[69]\tvalidation_0-auc:0.88741\n[70]\tvalidation_0-auc:0.88731\n[71]\tvalidation_0-auc:0.88734\n[72]\tvalidation_0-auc:0.88734\n[73]\tvalidation_0-auc:0.88735\n[74]\tvalidation_0-auc:0.88734\n[75]\tvalidation_0-auc:0.88732\n[76]\tvalidation_0-auc:0.88731\n[77]\tvalidation_0-auc:0.88726\n[78]\tvalidation_0-auc:0.88736\n[79]\tvalidation_0-auc:0.88732\n[80]\tvalidation_0-auc:0.88733\n[81]\tvalidation_0-auc:0.88730\n[82]\tvalidation_0-auc:0.88722\n[83]\tvalidation_0-auc:0.88717\n[84]\tvalidation_0-auc:0.88716\n[85]\tvalidation_0-auc:0.88722\n[86]\tvalidation_0-auc:0.88719\n[87]\tvalidation_0-auc:0.88720\n[88]\tvalidation_0-auc:0.88719\n[89]\tvalidation_0-auc:0.88721\n[90]\tvalidation_0-auc:0.88721\n[91]\tvalidation_0-auc:0.88722\n[92]\tvalidation_0-auc:0.88720\n[93]\tvalidation_0-auc:0.88721\n[94]\tvalidation_0-auc:0.88721\n[95]\tvalidation_0-auc:0.88721\n[96]\tvalidation_0-auc:0.88719\n[97]\tvalidation_0-auc:0.88718\n[98]\tvalidation_0-auc:0.88716\n[99]\tvalidation_0-auc:0.88715\n: XGB - ROC AUC Score = 0.8871533786098678\n[1]\tvalid_0's auc: 0.854355\n[2]\tvalid_0's auc: 0.858471\n[3]\tvalid_0's auc: 0.862125\n[4]\tvalid_0's auc: 0.864378\n[5]\tvalid_0's auc: 0.866176\n[6]\tvalid_0's auc: 0.867944\n[7]\tvalid_0's auc: 0.87005\n[8]\tvalid_0's auc: 0.870879\n[9]\tvalid_0's auc: 0.87218\n[10]\tvalid_0's auc: 0.873038\n[11]\tvalid_0's auc: 0.873917\n[12]\tvalid_0's auc: 0.874482\n[13]\tvalid_0's auc: 0.875358\n[14]\tvalid_0's auc: 0.875945\n[15]\tvalid_0's auc: 0.876772\n[16]\tvalid_0's auc: 0.877237\n[17]\tvalid_0's auc: 0.87776\n[18]\tvalid_0's auc: 0.878181\n[19]\tvalid_0's auc: 0.878525\n[20]\tvalid_0's auc: 0.878879\n[21]\tvalid_0's auc: 0.879358\n[22]\tvalid_0's auc: 0.879685\n[23]\tvalid_0's auc: 0.880193\n[24]\tvalid_0's auc: 0.880504\n[25]\tvalid_0's auc: 0.880953\n[26]\tvalid_0's auc: 0.881459\n[27]\tvalid_0's auc: 0.881921\n[28]\tvalid_0's auc: 0.882205\n[29]\tvalid_0's auc: 0.88256\n[30]\tvalid_0's auc: 0.882945\n[31]\tvalid_0's auc: 0.883266\n[32]\tvalid_0's auc: 0.883464\n[33]\tvalid_0's auc: 0.883681\n[34]\tvalid_0's auc: 0.883936\n[35]\tvalid_0's auc: 0.884208\n[36]\tvalid_0's auc: 0.884398\n[37]\tvalid_0's auc: 0.884646\n[38]\tvalid_0's auc: 0.884922\n[39]\tvalid_0's auc: 0.885108\n[40]\tvalid_0's auc: 0.885387\n[41]\tvalid_0's auc: 0.885578\n[42]\tvalid_0's auc: 0.885711\n[43]\tvalid_0's auc: 0.885865\n[44]\tvalid_0's auc: 0.886053\n[45]\tvalid_0's auc: 0.886237\n[46]\tvalid_0's auc: 0.886343\n[47]\tvalid_0's auc: 0.886502\n[48]\tvalid_0's auc: 0.886679\n[49]\tvalid_0's auc: 0.886882\n[50]\tvalid_0's auc: 0.886966\n[51]\tvalid_0's auc: 0.887136\n[52]\tvalid_0's auc: 0.887295\n[53]\tvalid_0's auc: 0.887347\n[54]\tvalid_0's auc: 0.887438\n[55]\tvalid_0's auc: 0.887526\n[56]\tvalid_0's auc: 0.887625\n[57]\tvalid_0's auc: 0.887738\n[58]\tvalid_0's auc: 0.887827\n[59]\tvalid_0's auc: 0.887887\n[60]\tvalid_0's auc: 0.887939\n[61]\tvalid_0's auc: 0.888026\n[62]\tvalid_0's auc: 0.888083\n[63]\tvalid_0's auc: 0.888147\n[64]\tvalid_0's auc: 0.888187\n[65]\tvalid_0's auc: 0.888261\n[66]\tvalid_0's auc: 0.888306\n[67]\tvalid_0's auc: 0.888394\n[68]\tvalid_0's auc: 0.888427\n[69]\tvalid_0's auc: 0.888462\n[70]\tvalid_0's auc: 0.888567\n[71]\tvalid_0's auc: 0.888641\n[72]\tvalid_0's auc: 0.88865\n[73]\tvalid_0's auc: 0.888672\n[74]\tvalid_0's auc: 0.888724\n[75]\tvalid_0's auc: 0.888776\n[76]\tvalid_0's auc: 0.888838\n[77]\tvalid_0's auc: 0.888855\n[78]\tvalid_0's auc: 0.88888\n[79]\tvalid_0's auc: 0.888902\n[80]\tvalid_0's auc: 0.888936\n[81]\tvalid_0's auc: 0.888995\n[82]\tvalid_0's auc: 0.889058\n[83]\tvalid_0's auc: 0.88909\n[84]\tvalid_0's auc: 0.88913\n[85]\tvalid_0's auc: 0.889157\n[86]\tvalid_0's auc: 0.889185\n[87]\tvalid_0's auc: 0.889251\n[88]\tvalid_0's auc: 0.889299\n[89]\tvalid_0's auc: 0.889365\n[90]\tvalid_0's auc: 0.889375\n[91]\tvalid_0's auc: 0.889401\n[92]\tvalid_0's auc: 0.889417\n[93]\tvalid_0's auc: 0.889448\n[94]\tvalid_0's auc: 0.889486\n[95]\tvalid_0's auc: 0.889499\n[96]\tvalid_0's auc: 0.88947\n[97]\tvalid_0's auc: 0.889514\n[98]\tvalid_0's auc: 0.889518\n[99]\tvalid_0's auc: 0.889559\n[100]\tvalid_0's auc: 0.889568\n: LGB - ROC AUC Score = 0.889568201702617\n: CB - ROC AUC Score = 0.8923561200581146\n: KNN - ROC AUC Score = 0.8323463204675339\n--> Overall metrics\n: XGB - ROC AUC Score = 0.8892509932407815\n: LGB - ROC AUC Score = 0.8913070461144398\n: CB - ROC AUC Score = 0.8942973917816135\n: KNN - ROC AUC Score = 0.8340251344295531\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 2021\nn_folds = 5\nk_fold = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n\nl1_train = pd.DataFrame(data={\n    \"xgb\": xgb_train_preds.tolist(),\n    \"lgb\": lgb_train_preds.tolist(),\n    \"cb\": cb_train_preds.tolist(),\n    \"knn\": knn_train_preds.tolist()\n})\nl1_test = pd.DataFrame(data={\n    \"xgb\": xgb_test_preds.tolist(),\n    \"lgb\": lgb_test_preds.tolist(),\n    \"cb\": cb_test_preds.tolist(),\n    \"knn\": knn_test_preds.tolist()\n})\n\ntrain_preds = np.zeros(len(l1_train.index), )\ntest_preds = np.zeros(len(l1_test.index), )\nfeatures = [\"xgb\", \"lgb\", \"cb\", \"knn\"]\n\nfor fold, (train_index, test_index) in enumerate(k_fold.split(l1_train, target)):\n    print(\"--> Fold {}\".format(fold + 1))\n    y_train = target.iloc[train_index]\n    y_valid = target.iloc[test_index]\n\n    x_train = pd.DataFrame(l1_train[features].iloc[train_index])\n    x_valid = pd.DataFrame(l1_train[features].iloc[test_index])\n    \n    model = XGBClassifier(random_state=random_state)\n    model.fit(\n        x_train,\n        y_train,\n    )\n\n    train_oof_preds = model.predict_proba(x_valid)[:,-1]\n    test_oof_preds = model.predict_proba(l1_test[features])[:,-1]\n    train_preds[test_index] = train_oof_preds\n    test_preds += test_oof_preds / n_folds\n    print(\": ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n    print(\"\")\n    \nprint(\"--> Overall metrics\")\nprint(\": ROC AUC Score = {}\".format(roc_auc_score(target, train_preds, average=\"micro\")))","execution_count":21,"outputs":[{"output_type":"stream","text":"--> Fold 1\n[10:12:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n: ROC AUC Score = 0.8950426009976062\n\n--> Fold 2\n[10:12:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n: ROC AUC Score = 0.8924715393794299\n\n--> Fold 3\n[10:12:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n: ROC AUC Score = 0.8941091390989113\n\n--> Fold 4\n[10:13:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n: ROC AUC Score = 0.8957667876272667\n\n--> Fold 5\n[10:13:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n: ROC AUC Score = 0.8918412936173982\n\n--> Overall metrics\n: ROC AUC Score = 0.8937907560189443\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit[\"target\"] = test_preds.tolist()\n# submit.to_csv(\"20210313_stacking_submit.csv\", index=False)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit.to_csv('all_gmmclass_submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}