{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.read_csv('../input/month-dacon11/train_features.csv')\ny_train=pd.read_csv('../input/month-dacon11/train_labels.csv')\n\nsamples=75\ntime_series=600\nstart_x=X_train.shape[0]-samples*time_series\nX_train_new,X_test_new=X_train.iloc[:start_x],X_train.iloc[start_x:]\n\nstart_y=y_train.shape[0]-samples\ny_train_new,y_test_new=y_train.iloc[:start_y],y_train.iloc[start_y:]\nX_train_new.head(5)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   id  time     acc_x     acc_y     acc_z      gy_x       gy_y       gy_z\n0   0     0  1.206087 -0.179371 -0.148447 -0.591608 -30.549010 -31.676112\n1   0     1  1.287696 -0.198974 -0.182444  0.303100 -39.139103 -24.927216\n2   0     2  1.304609 -0.195114 -0.253382 -3.617278 -44.122565 -25.019629\n3   0     3  1.293095 -0.230366 -0.215210  2.712986 -53.597843 -27.454013\n4   0     4  1.300887 -0.187757 -0.222523  4.286707 -57.906561 -27.961234","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>time</th>\n      <th>acc_x</th>\n      <th>acc_y</th>\n      <th>acc_z</th>\n      <th>gy_x</th>\n      <th>gy_y</th>\n      <th>gy_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1.206087</td>\n      <td>-0.179371</td>\n      <td>-0.148447</td>\n      <td>-0.591608</td>\n      <td>-30.549010</td>\n      <td>-31.676112</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1.287696</td>\n      <td>-0.198974</td>\n      <td>-0.182444</td>\n      <td>0.303100</td>\n      <td>-39.139103</td>\n      <td>-24.927216</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1.304609</td>\n      <td>-0.195114</td>\n      <td>-0.253382</td>\n      <td>-3.617278</td>\n      <td>-44.122565</td>\n      <td>-25.019629</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1.293095</td>\n      <td>-0.230366</td>\n      <td>-0.215210</td>\n      <td>2.712986</td>\n      <td>-53.597843</td>\n      <td>-27.454013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1.300887</td>\n      <td>-0.187757</td>\n      <td>-0.222523</td>\n      <td>4.286707</td>\n      <td>-57.906561</td>\n      <td>-27.961234</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new=X_train_new.drop(['id','time'],axis=1)\nX_test_new=X_test_new.drop(['id','time'], axis=1)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_new.head(5)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   id  label                 label_desc\n0   0     37  Shoulder Press (dumbbell)\n1   1     26               Non-Exercise\n2   2      3         Biceps Curl (band)\n3   3     26               Non-Exercise\n4   4     26               Non-Exercise","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>label_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>37</td>\n      <td>Shoulder Press (dumbbell)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>26</td>\n      <td>Non-Exercise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>Biceps Curl (band)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>26</td>\n      <td>Non-Exercise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>26</td>\n      <td>Non-Exercise</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_new=y_train_new.drop(['id','label_desc'],axis=1)\ny_test_new=y_test_new.drop(['id','label_desc'],axis=1)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new=X_train_new.values\nX_test_new=X_test_new.values\ny_train_new=y_train_new.values\ny_test_new=y_test_new.values\nprint('The size of X_train_new:', X_train_new.shape )\nprint('The size of X_test_new:', X_test_new.shape )\n\nprint('The size of y_train_new:', y_train_new.shape )\nprint('The size of y_test_new:', y_test_new.shape )","execution_count":6,"outputs":[{"output_type":"stream","text":"The size of X_train_new: (1830000, 6)\nThe size of X_test_new: (45000, 6)\nThe size of y_train_new: (3050, 1)\nThe size of y_test_new: (75, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ny=np.concatenate([y_train_new,y_test_new])\ny=to_categorical(y)\n\ny_train_new = y[:-75]\ny_test_new = y[-75:]\nprint('The shape of y_train_new:', y_train_new.shape)\nprint('The shape of y_test_new:', y_test_new.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"The shape of y_train_new: (3050, 61)\nThe shape of y_test_new: (75, 61)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nfeatures=X_train_new.shape[1]\nntimestamp=600\nnsamples=3050\nX_3D_train=X_train_new[:,0].reshape(nsamples,ntimestamp)\nfor i in range(nfeatures-1):\n  i=i+1\n  r=X_train_new[:,i].reshape(nsamples,ntimestamp)\n  X_3D_train=np.dstack((X_3D_train,r))\nprint('The shape of X_train: ', X_3D_train.shape)\n\nnfeatures=X_test_new.shape[1]\nntimestamp=600\nnsamples=75\nX_3D_test=X_test_new[:,0].reshape(nsamples,ntimestamp)\nfor i in range(nfeatures-1):\n  i=i+1\n  r=X_test_new[:,i].reshape(nsamples,ntimestamp)\n  X_3D_test=np.dstack((X_3D_test,r))\nprint('The shape of X_test: ', X_3D_test.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"The shape of X_train:  (3050, 600, 6)\nThe shape of X_test:  (75, 600, 6)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nfeatures=X_3D_train.shape[2]\nntimestamp=X_3D_train.shape[1]\nnsamples=X_3D_train.shape[0]\n\nprint('Number of features in Xtrain: ', nfeatures)\nprint('Number of timestamps in Xtrain: ', ntimestamp)\nprint('Number of samples in Xtrain: ', nsamples)","execution_count":9,"outputs":[{"output_type":"stream","text":"Number of features in Xtrain:  6\nNumber of timestamps in Xtrain:  600\nNumber of samples in Xtrain:  3050\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(nfeatures):\n    X_train_m = np.mean(X_3D_train[:,:,k])\n    X_train_sd = np.std(X_3D_train[:,:,k])\n    X_3D_train[:,:,k] = (X_3D_train[:,:,k]-X_train_m)/X_train_sd\n\nfor k in range(nfeatures):\n    X_test_m = np.mean(X_3D_test[:,:,k])\n    X_test_sd = np.std(X_3D_test[:,:,k])\n    X_3D_test[:,:,k] = (X_3D_test[:,:,k]-X_test_m)/X_test_sd","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LSTM\nfrom keras.layers import Activation\nfrom keras import activations\n\nfrom keras.layers.convolutional import Conv1D\nfrom keras.optimizers import Adam\nfrom keras.initializers import GlorotNormal\n\noptimizer=Adam(learning_rate=0.0005)\ninitializer=GlorotNormal()\n# https://keras.io/api/layers/initializers/\n\nfor k in range(1):\n  verbose,epochs,batch_size=1,100,64\n  model=Sequential()\n  model.add(Conv1D(filters=16,kernel_size=3,\n                   input_shape=(ntimestamp,nfeatures),\n                   kernel_initializer=initializer))\n  model.add(BatchNormalization())\n  model.add(Activation(activations.relu))\n  model.add(Conv1D(filters=32,kernel_size=3,kernel_initializer=initializer))\n  model.add(BatchNormalization())\n  model.add(Activation(activations.relu))\n  model.add(LSTM(128))\n  model.add(Dense(y_train_new.shape[1],activation='softmax'))\n  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n# fit network","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":28,"outputs":[{"output_type":"stream","text":"Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_24 (Conv1D)           (None, 598, 16)           304       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 598, 16)           64        \n_________________________________________________________________\nactivation (Activation)      (None, 598, 16)           0         \n_________________________________________________________________\nconv1d_25 (Conv1D)           (None, 596, 32)           1568      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 596, 32)           128       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 596, 32)           0         \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 128)               82432     \n_________________________________________________________________\ndense_11 (Dense)             (None, 61)                7869      \n=================================================================\nTotal params: 92,365\nTrainable params: 92,269\nNon-trainable params: 96\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_3D_train,y_train_new,epochs=epochs,batch_size=batch_size,verbose=verbose)","execution_count":29,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n48/48 [==============================] - 6s 34ms/step - loss: 3.2580 - accuracy: 0.3978\nEpoch 2/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.5486 - accuracy: 0.4900\nEpoch 3/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.2833 - accuracy: 0.5038\nEpoch 4/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.2161 - accuracy: 0.5142\nEpoch 5/100\n48/48 [==============================] - 2s 34ms/step - loss: 2.2698 - accuracy: 0.5133\nEpoch 6/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.2497 - accuracy: 0.5132\nEpoch 7/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.1461 - accuracy: 0.5275\nEpoch 8/100\n48/48 [==============================] - 2s 33ms/step - loss: 2.1145 - accuracy: 0.5259\nEpoch 9/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.9475 - accuracy: 0.5445\nEpoch 10/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.9152 - accuracy: 0.5611\nEpoch 11/100\n48/48 [==============================] - 2s 34ms/step - loss: 2.3907 - accuracy: 0.5014\nEpoch 12/100\n48/48 [==============================] - 2s 35ms/step - loss: 2.0429 - accuracy: 0.5419\nEpoch 13/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.9075 - accuracy: 0.5702\nEpoch 14/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.8782 - accuracy: 0.5630\nEpoch 15/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.8936 - accuracy: 0.5606\nEpoch 16/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.9552 - accuracy: 0.5457\nEpoch 17/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.8796 - accuracy: 0.5625\nEpoch 18/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.7519 - accuracy: 0.5775\nEpoch 19/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.7511 - accuracy: 0.5747\nEpoch 20/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.7336 - accuracy: 0.5753\nEpoch 21/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.7151 - accuracy: 0.5837\nEpoch 22/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.6790 - accuracy: 0.5838\nEpoch 23/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.6879 - accuracy: 0.5750\nEpoch 24/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.6700 - accuracy: 0.5887\nEpoch 25/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.6026 - accuracy: 0.5884\nEpoch 26/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.6537 - accuracy: 0.5713\nEpoch 27/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.5534 - accuracy: 0.6027\nEpoch 28/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4818 - accuracy: 0.6190\nEpoch 29/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4460 - accuracy: 0.6220\nEpoch 30/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4719 - accuracy: 0.6169\nEpoch 31/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.6795 - accuracy: 0.5762\nEpoch 32/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.5318 - accuracy: 0.6047\nEpoch 33/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.4609 - accuracy: 0.6226\nEpoch 34/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4501 - accuracy: 0.6090\nEpoch 35/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4455 - accuracy: 0.6174\nEpoch 36/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.5739 - accuracy: 0.5980\nEpoch 37/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4699 - accuracy: 0.6083\nEpoch 38/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.4289 - accuracy: 0.6213\nEpoch 39/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.3950 - accuracy: 0.6156\nEpoch 40/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.3356 - accuracy: 0.6417\nEpoch 41/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.3357 - accuracy: 0.6302\nEpoch 42/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2917 - accuracy: 0.6477\nEpoch 43/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2461 - accuracy: 0.6510\nEpoch 44/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2722 - accuracy: 0.6526\nEpoch 45/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2282 - accuracy: 0.6575\nEpoch 46/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.1611 - accuracy: 0.6888\nEpoch 47/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2915 - accuracy: 0.6431\nEpoch 48/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2171 - accuracy: 0.6595\nEpoch 49/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.2387 - accuracy: 0.6596\nEpoch 50/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.1450 - accuracy: 0.6892\nEpoch 51/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.1859 - accuracy: 0.6583\nEpoch 52/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2766 - accuracy: 0.6428\nEpoch 53/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.1549 - accuracy: 0.6742\nEpoch 54/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.2428 - accuracy: 0.6719\nEpoch 55/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.1826 - accuracy: 0.6634\nEpoch 56/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.1184 - accuracy: 0.6879\nEpoch 57/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.1187 - accuracy: 0.6789\nEpoch 58/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.0971 - accuracy: 0.6972\nEpoch 59/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.0539 - accuracy: 0.6953\nEpoch 60/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.0714 - accuracy: 0.6825\nEpoch 61/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2146 - accuracy: 0.6657\nEpoch 62/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.0916 - accuracy: 0.6943\nEpoch 63/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.2569 - accuracy: 0.6493\nEpoch 64/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.1177 - accuracy: 0.6799\nEpoch 65/100\n48/48 [==============================] - 2s 33ms/step - loss: 1.0081 - accuracy: 0.7037\nEpoch 66/100\n48/48 [==============================] - 2s 34ms/step - loss: 1.0362 - accuracy: 0.7001\nEpoch 67/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.9689 - accuracy: 0.7235\nEpoch 68/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.9417 - accuracy: 0.7358\nEpoch 69/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.9399 - accuracy: 0.7301\nEpoch 70/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.9959 - accuracy: 0.7121\nEpoch 71/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.9273 - accuracy: 0.7348\nEpoch 72/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.9058 - accuracy: 0.7265\nEpoch 73/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8514 - accuracy: 0.7575\nEpoch 74/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8600 - accuracy: 0.7486\nEpoch 75/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8671 - accuracy: 0.7557\nEpoch 76/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8934 - accuracy: 0.7456\nEpoch 77/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8819 - accuracy: 0.7472\nEpoch 78/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8918 - accuracy: 0.7436\nEpoch 79/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8605 - accuracy: 0.7416\nEpoch 80/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8104 - accuracy: 0.7628\nEpoch 81/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8694 - accuracy: 0.7397\nEpoch 82/100\n","name":"stdout"},{"output_type":"stream","text":"48/48 [==============================] - 2s 33ms/step - loss: 0.7863 - accuracy: 0.7772\nEpoch 83/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7658 - accuracy: 0.7805\nEpoch 84/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7814 - accuracy: 0.7812\nEpoch 85/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8270 - accuracy: 0.7655\nEpoch 86/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.8305 - accuracy: 0.7550\nEpoch 87/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.7906 - accuracy: 0.7656\nEpoch 88/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7659 - accuracy: 0.7733\nEpoch 89/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7958 - accuracy: 0.7631\nEpoch 90/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7314 - accuracy: 0.7854\nEpoch 91/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7621 - accuracy: 0.7824\nEpoch 92/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7911 - accuracy: 0.7678\nEpoch 93/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8386 - accuracy: 0.7472\nEpoch 94/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.7630 - accuracy: 0.7705\nEpoch 95/100\n48/48 [==============================] - 2s 34ms/step - loss: 0.7658 - accuracy: 0.7781\nEpoch 96/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8702 - accuracy: 0.7485\nEpoch 97/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8731 - accuracy: 0.7389\nEpoch 98/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7519 - accuracy: 0.7733\nEpoch 99/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.8375 - accuracy: 0.7448\nEpoch 100/100\n48/48 [==============================] - 2s 33ms/step - loss: 0.7708 - accuracy: 0.7691\n","name":"stdout"},{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f3a3c53d3d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate\nnp.mean(np.argmax(yhat,axis=1)==np.argmax(y_test_new,axis=1))","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"0.6"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('../input/month-dacon11/test_features.csv')\n\nX_test_3D=test.drop(['id','time'],axis=1).values.reshape(-1,600,6)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(X_test_3D)","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit=pd.read_csv('../input/month-dacon11/sample_submission.csv')\nsubmit.iloc[:,1:]=pred\nsubmit.head()","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"     id         0         1         2         3         4         5         6  \\\n0  3125  0.000880  0.000142  0.000006  0.000095  0.001231  0.004425  0.000014   \n1  3126  0.000468  0.000377  0.000004  0.000032  0.000900  0.000323  0.000156   \n2  3127  0.000879  0.000158  0.000001  0.000008  0.003097  0.001298  0.000006   \n3  3128  0.026090  0.001311  0.000030  0.000405  0.004536  0.004897  0.000108   \n4  3129  0.008258  0.000185  0.000003  0.000031  0.004468  0.003955  0.000025   \n\n          7             8  ...        51            52        53  \\\n0  0.000148  1.905429e-06  ...  0.000026  8.060777e-08  0.000089   \n1  0.000499  6.487138e-07  ...  0.000008  4.524130e-08  0.000006   \n2  0.001082  5.130681e-07  ...  0.000009  1.585317e-07  0.000012   \n3  0.012751  3.072149e-06  ...  0.000621  7.524662e-07  0.000370   \n4  0.010643  1.062241e-06  ...  0.000396  2.534847e-07  0.000094   \n\n             54        55        56        57            58        59  \\\n0  1.872273e-06  0.000145  0.000066  0.000006  9.374644e-07  0.009808   \n1  6.125589e-07  0.000047  0.000007  0.000111  8.640509e-07  0.154934   \n2  1.661962e-07  0.000008  0.000034  0.000019  4.832122e-07  0.008822   \n3  4.098767e-06  0.000255  0.000027  0.000534  7.234331e-06  0.047945   \n4  7.082789e-07  0.000029  0.000033  0.000042  9.665177e-07  0.003426   \n\n             60  \n0  4.455566e-07  \n1  3.810322e-06  \n2  9.634643e-07  \n3  9.016141e-06  \n4  9.975045e-07  \n\n[5 rows x 62 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3125</td>\n      <td>0.000880</td>\n      <td>0.000142</td>\n      <td>0.000006</td>\n      <td>0.000095</td>\n      <td>0.001231</td>\n      <td>0.004425</td>\n      <td>0.000014</td>\n      <td>0.000148</td>\n      <td>1.905429e-06</td>\n      <td>...</td>\n      <td>0.000026</td>\n      <td>8.060777e-08</td>\n      <td>0.000089</td>\n      <td>1.872273e-06</td>\n      <td>0.000145</td>\n      <td>0.000066</td>\n      <td>0.000006</td>\n      <td>9.374644e-07</td>\n      <td>0.009808</td>\n      <td>4.455566e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3126</td>\n      <td>0.000468</td>\n      <td>0.000377</td>\n      <td>0.000004</td>\n      <td>0.000032</td>\n      <td>0.000900</td>\n      <td>0.000323</td>\n      <td>0.000156</td>\n      <td>0.000499</td>\n      <td>6.487138e-07</td>\n      <td>...</td>\n      <td>0.000008</td>\n      <td>4.524130e-08</td>\n      <td>0.000006</td>\n      <td>6.125589e-07</td>\n      <td>0.000047</td>\n      <td>0.000007</td>\n      <td>0.000111</td>\n      <td>8.640509e-07</td>\n      <td>0.154934</td>\n      <td>3.810322e-06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3127</td>\n      <td>0.000879</td>\n      <td>0.000158</td>\n      <td>0.000001</td>\n      <td>0.000008</td>\n      <td>0.003097</td>\n      <td>0.001298</td>\n      <td>0.000006</td>\n      <td>0.001082</td>\n      <td>5.130681e-07</td>\n      <td>...</td>\n      <td>0.000009</td>\n      <td>1.585317e-07</td>\n      <td>0.000012</td>\n      <td>1.661962e-07</td>\n      <td>0.000008</td>\n      <td>0.000034</td>\n      <td>0.000019</td>\n      <td>4.832122e-07</td>\n      <td>0.008822</td>\n      <td>9.634643e-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3128</td>\n      <td>0.026090</td>\n      <td>0.001311</td>\n      <td>0.000030</td>\n      <td>0.000405</td>\n      <td>0.004536</td>\n      <td>0.004897</td>\n      <td>0.000108</td>\n      <td>0.012751</td>\n      <td>3.072149e-06</td>\n      <td>...</td>\n      <td>0.000621</td>\n      <td>7.524662e-07</td>\n      <td>0.000370</td>\n      <td>4.098767e-06</td>\n      <td>0.000255</td>\n      <td>0.000027</td>\n      <td>0.000534</td>\n      <td>7.234331e-06</td>\n      <td>0.047945</td>\n      <td>9.016141e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3129</td>\n      <td>0.008258</td>\n      <td>0.000185</td>\n      <td>0.000003</td>\n      <td>0.000031</td>\n      <td>0.004468</td>\n      <td>0.003955</td>\n      <td>0.000025</td>\n      <td>0.010643</td>\n      <td>1.062241e-06</td>\n      <td>...</td>\n      <td>0.000396</td>\n      <td>2.534847e-07</td>\n      <td>0.000094</td>\n      <td>7.082789e-07</td>\n      <td>0.000029</td>\n      <td>0.000033</td>\n      <td>0.000042</td>\n      <td>9.665177e-07</td>\n      <td>0.003426</td>\n      <td>9.975045e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 62 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('cnn_lstm_1.csv',index=False)","execution_count":78,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}