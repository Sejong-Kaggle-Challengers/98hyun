{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/dacon9/open/train.csv')\ntest=pd.read_csv('../input/dacon9/open/test_x.csv')\nsubmit=pd.read_csv('../input/dacon9/open/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# author의 분포를 확인했다. balance인지 모르겠다.\n\ntemp=train['author'].value_counts()\n\nfig,ax=plt.subplots(1,1,figsize=(10,10),dpi=200)\n\nax.bar(temp.index,temp.values)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 단어의 수를 봤다. 많은지 모르겠다.\n\ntemp=train['text'].apply(lambda x:len(x.split()))\n\ntemp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf-idf\n\n#### 사용하는 이유\n\n1. 특징 추출 - 수치화\n2. countvectorizer도 있다. 이건 조사같이 의미없는 단어에 높은 점수를 줄 수 있다는 한계점이 있다. \n3. 즉, tf가 advantage, idf가 disadvantage. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# 출처: https://chan-lab.tistory.com/24?category=810217 [은공지능 공작소]\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntext = ['I go to my home my home is very large', # Doc[0]\n        'I went out my home I go to the market', # Doc[1] \n        'I bought a yellow lemon I go back to home'] # Doc[2] \ntfidf_vectorizer = TfidfVectorizer() # TF-IDF 객체선언","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer.fit(text) # 단어를 학습시킴 \n# tfidf_vectorizer.vocabulary_ # 단어사전을 출력 \n# sorted(tfidf_vectorizer.vocabulary_.items()) # 단어사전 정렬\n\n# tfidf_vectorizer.idf_ # idf \ntfidf_vectorizer.transform(text).toarray() # 최종 tf-idf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### baseline "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import log_loss, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text']=train['text'].apply(lambda x:x.lower())\n# train['text']=train['text'].apply(lambda x:re.sub(r'[\\.,“”!?]','',x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['index'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr,X_val,y_tr,y_val=train_test_split(train['text'],train['author'],test_size=0.2,\n                                               stratify=train['author'],random_state=71)\nprint(X_tr.shape,X_val.shape,y_tr.shape,y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer=TfidfVectorizer(min_df=2)\nscaler=MaxAbsScaler()\nclassifier=BernoulliNB(binarize=0, alpha=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pl=make_pipeline(vectorizer,classifier)\npl.fit(X_tr,y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_prob=pl.predict_proba(X_val)\npreds_class=pl.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_loss=log_loss(y_val,preds_prob)\nprint(nb_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_val,preds_class))\nprint('\\n')\nprint(classification_report(y_val,preds_class))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ALBERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow_text==2.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\nimport tensorflow_hub as hub\nimport tensorflow_text as text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model():\n    text_input=tensorflow.keras.layers.Input(shape=(),dtype=tensorflow.string)\n    preprocessing_layer=hub.KerasLayer(\"http://tfhub.dev/tensorflow/albert_en_preprocess/2\")\n    encoder_inputs=preprocessing_layer(text_input)\n    encoder=hub.KerasLayer('https://tfhub.dev/tensorflow/albert_en_base/2',trainable=True)\n    outputs=encoder(encoder_inputs)\n    pooled_output=outputs[\"pooled_output\"]\n    output=tensorflow.keras.layers.Dropout(0.5)(pooled_output)\n    output=tensorflow.keras.layers.Dense(5,activation='softmax')(output)\n    return tensorflow.keras.Model(text_input,output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_model=model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q tf-models-official\nfrom official.nlp import optimization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_train,tf_val=train_test_split(train,test_size=0.2,stratify=train['author'],random_state=71)\nprint(tf_train.shape,tf_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_to_dataset(df,batch_size=47):\n    temp=df.copy()\n    targets=temp.pop('author')\n    ds=tensorflow.data.Dataset.from_tensor_slices((dict(temp),targets))\n    ds=ds.batch(batch_size)\n    return ds\n\ntr_ds=df_to_dataset(tf_train)\nval_ds=df_to_dataset(tf_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=3\nsteps_per_epoch=tensorflow.data.experimental.cardinality(tr_ds).numpy()\nnum_train_steps=steps_per_epoch*epochs\nnum_warmup_steps=int(0.1*num_train_steps)\n\noptimizer=optimization.create_optimizer(init_lr=3e-5,\n                                        num_train_steps=num_train_steps,\n                                        num_warmup_steps=num_warmup_steps,\n                                        optimizer_type='adamw')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_model.compile(optimizer=optimizer,\n                   loss='sparse_categorical_crossentropy',\n                   metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch_size가 크면 그만큼 기억할게 많아지니까 out of memory 나고.\n# 그렇다고 batch_size가 작아지면 돌릴게 많아지니까 memory가 남아도 느리게 놀아가고. \n\n# 일단 이렇게 돌리면 13시간 나온다. \n\nwith tensorflow.device('/device:GPU:0'):\n    history=text_model.fit(x=tr_ds,validation_data=val_ds,batch_size=47,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_model.evaluate(tr_ds,batch_size=47)\ntext_model.evaluate(val_ds,batch_size=47)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_preds=text_model.predict(val_ds)\nalbert_loss=log_loss(y_val,tf_preds)\nprint(albert_loss)\n\ntf_preds_class=np.argmax(tf_preds,axis=1)\n\nprint(confusion_matrix(y_test, tf_preds_class))\nprint('\\n')\nprint(classification_report(y_test, tf_preds_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=text_model.predict(test['text'].values)\npreds_df=pd.DataFrame(data=preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit=pd.concat([test,preds_df],axis=1)\nsubmit.drop(columns='text',inplace=True)\nsubmit.to_csv('submit.csv',index=False,index_label=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}