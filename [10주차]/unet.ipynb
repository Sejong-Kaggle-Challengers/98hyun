{"cells":[{"metadata":{},"cell_type":"markdown","source":"### torch 정보와 library"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchinfo","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting torchinfo\n  Downloading torchinfo-0.0.8-py3-none-any.whl (16 kB)\nInstalling collected packages: torchinfo\nSuccessfully installed torchinfo-0.0.8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nfrom torchinfo import summary","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://github.com/ugent-korea/pytorch-unet-segmentation/raw/master/readme_images/UNet_custom_parameter.png)"},{"metadata":{},"cell_type":"markdown","source":"### 2가지 방법의 unet"},{"metadata":{},"cell_type":"markdown","source":"https://github.com/ugent-korea/pytorch-unet-segmentation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"class UNet(nn.Module):\n\n    def __init__(self):\n\n        super(UNet, self).__init__()\n\n        # Conv block 1 - Down 1\n        self.conv1_block = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=32, out_channels=32,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Conv block 2 - Down 2\n        self.conv2_block = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Conv block 3 - Down 3\n        self.conv3_block = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=128, out_channels=128,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Conv block 4 - Down 4\n        self.conv4_block = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=256, out_channels=256,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n        self.max4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Conv block 5 - Down 5\n        self.conv5_block = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=512, out_channels=512,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # Up 1\n        self.up_1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n\n        # Up Conv block 1\n        self.conv_up_1 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=256,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=256, out_channels=256,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # Up 2\n        self.up_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n\n        # Up Conv block 2\n        self.conv_up_2 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=128,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=128, out_channels=128,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # Up 3\n        self.up_3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n\n        # Up Conv block 3\n        self.conv_up_3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=64,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # Up 4\n        self.up_4 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=2, stride=2)\n\n        # Up Conv block 4\n        self.conv_up_4 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=32,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=32, out_channels=32,\n                      kernel_size=3, padding=0, stride=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # Final output\n        self.conv_final = nn.Conv2d(in_channels=32, out_channels=2,\n                                    kernel_size=1, padding=0, stride=1)\n\n    def forward(self, x):\n\n        # Down 1\n        x = self.conv1_block(x)\n        conv1_out = x  # Save out1\n        conv1_dim = x.shape[2]\n        x = self.max1(x)\n\n        # Down 2\n        x = self.conv2_block(x)\n        conv2_out = x\n        conv2_dim = x.shape[2]\n        x = self.max2(x)\n\n        # Down 3\n        x = self.conv3_block(x)\n        conv3_out = x\n        conv3_dim = x.shape[2]\n        x = self.max3(x)\n\n        # Down 4\n        x = self.conv4_block(x)\n        conv4_out = x\n        conv4_dim = x.shape[2]\n        x = self.max4(x)\n\n        # Midpoint\n        x = self.conv5_block(x)\n\n        # Up 1\n        x = self.up_1(x)\n        lower = int((conv4_dim - x.shape[2]) / 2)\n        upper = int(conv4_dim - lower)\n        conv4_out_modified = conv4_out[:, :, lower:upper, lower:upper]\n        x = torch.cat([x, conv4_out_modified], dim=1)\n        x = self.conv_up_1(x)\n\n        # Up 2\n        x = self.up_2(x)\n        lower = int((conv3_dim - x.shape[2]) / 2)\n        upper = int(conv3_dim - lower)\n        conv3_out_modified = conv3_out[:, :, lower:upper, lower:upper]\n        x = torch.cat([x, conv3_out_modified], dim=1)\n        x = self.conv_up_2(x)\n\n        # Up 3\n        x = self.up_3(x)\n        lower = int((conv2_dim - x.shape[2]) / 2)\n        upper = int(conv2_dim - lower)\n        conv2_out_modified = conv2_out[:, :, lower:upper, lower:upper]\n        x = torch.cat([x, conv2_out_modified], dim=1)\n        x = self.conv_up_3(x)\n\n        # Up 4\n        x = self.up_4(x)\n        lower = int((conv1_dim - x.shape[2]) / 2)\n        upper = int(conv1_dim - lower)\n        conv1_out_modified = conv1_out[:, :, lower:upper, lower:upper]\n        x = torch.cat([x, conv1_out_modified], dim=1)\n        x = self.conv_up_4(x)\n\n        # Final output\n        x = self.conv_final(x)\n\n        return x","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=UNet()\nsummary(model,(1,1,572,572))","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [1, 32, 568, 568]         --\n|    └─Conv2d: 2-1                       [1, 32, 570, 570]         320\n|    └─ReLU: 2-2                         [1, 32, 570, 570]         --\n|    └─Conv2d: 2-3                       [1, 32, 568, 568]         9,248\n|    └─ReLU: 2-4                         [1, 32, 568, 568]         --\n├─MaxPool2d: 1-2                         [1, 32, 284, 284]         --\n├─Sequential: 1-3                        [1, 64, 280, 280]         --\n|    └─Conv2d: 2-5                       [1, 64, 282, 282]         18,496\n|    └─ReLU: 2-6                         [1, 64, 282, 282]         --\n|    └─Conv2d: 2-7                       [1, 64, 280, 280]         36,928\n|    └─ReLU: 2-8                         [1, 64, 280, 280]         --\n├─MaxPool2d: 1-4                         [1, 64, 140, 140]         --\n├─Sequential: 1-5                        [1, 128, 136, 136]        --\n|    └─Conv2d: 2-9                       [1, 128, 138, 138]        73,856\n|    └─ReLU: 2-10                        [1, 128, 138, 138]        --\n|    └─Conv2d: 2-11                      [1, 128, 136, 136]        147,584\n|    └─ReLU: 2-12                        [1, 128, 136, 136]        --\n├─MaxPool2d: 1-6                         [1, 128, 68, 68]          --\n├─Sequential: 1-7                        [1, 256, 64, 64]          --\n|    └─Conv2d: 2-13                      [1, 256, 66, 66]          295,168\n|    └─ReLU: 2-14                        [1, 256, 66, 66]          --\n|    └─Conv2d: 2-15                      [1, 256, 64, 64]          590,080\n|    └─ReLU: 2-16                        [1, 256, 64, 64]          --\n├─MaxPool2d: 1-8                         [1, 256, 32, 32]          --\n├─Sequential: 1-9                        [1, 512, 28, 28]          --\n|    └─Conv2d: 2-17                      [1, 512, 30, 30]          1,180,160\n|    └─ReLU: 2-18                        [1, 512, 30, 30]          --\n|    └─Conv2d: 2-19                      [1, 512, 28, 28]          2,359,808\n|    └─ReLU: 2-20                        [1, 512, 28, 28]          --\n├─ConvTranspose2d: 1-10                  [1, 256, 56, 56]          524,544\n├─Sequential: 1-11                       [1, 256, 52, 52]          --\n|    └─Conv2d: 2-21                      [1, 256, 54, 54]          1,179,904\n|    └─ReLU: 2-22                        [1, 256, 54, 54]          --\n|    └─Conv2d: 2-23                      [1, 256, 52, 52]          590,080\n|    └─ReLU: 2-24                        [1, 256, 52, 52]          --\n├─ConvTranspose2d: 1-12                  [1, 128, 104, 104]        131,200\n├─Sequential: 1-13                       [1, 128, 100, 100]        --\n|    └─Conv2d: 2-25                      [1, 128, 102, 102]        295,040\n|    └─ReLU: 2-26                        [1, 128, 102, 102]        --\n|    └─Conv2d: 2-27                      [1, 128, 100, 100]        147,584\n|    └─ReLU: 2-28                        [1, 128, 100, 100]        --\n├─ConvTranspose2d: 1-14                  [1, 64, 200, 200]         32,832\n├─Sequential: 1-15                       [1, 64, 196, 196]         --\n|    └─Conv2d: 2-29                      [1, 64, 198, 198]         73,792\n|    └─ReLU: 2-30                        [1, 64, 198, 198]         --\n|    └─Conv2d: 2-31                      [1, 64, 196, 196]         36,928\n|    └─ReLU: 2-32                        [1, 64, 196, 196]         --\n├─ConvTranspose2d: 1-16                  [1, 32, 392, 392]         8,224\n├─Sequential: 1-17                       [1, 32, 388, 388]         --\n|    └─Conv2d: 2-33                      [1, 32, 390, 390]         18,464\n|    └─ReLU: 2-34                        [1, 32, 390, 390]         --\n|    └─Conv2d: 2-35                      [1, 32, 388, 388]         9,248\n|    └─ReLU: 2-36                        [1, 32, 388, 388]         --\n├─Conv2d: 1-18                           [1, 2, 388, 388]          66\n==========================================================================================\nTotal params: 7,759,554\nTrainable params: 7,759,554\nNon-trainable params: 0\nTotal mult-adds (G): 41.89\n==========================================================================================\nInput size (MB): 1.31\nForward/backward pass size (MB): 538.62\nParams size (MB): 31.04\nEstimated Total Size (MB): 570.97\n=========================================================================================="},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"https://amaarora.github.io/2020/09/13/unet.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n        self.relu  = nn.ReLU()\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n    \n    def forward(self, x):\n        return self.conv2(self.relu(self.conv1(x)))\n\n\nclass Encoder(nn.Module):\n    def __init__(self, chs=(3,64,128,256,512,1024)):\n        super().__init__()\n        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n        self.pool       = nn.MaxPool2d(2)\n    \n    def forward(self, x):\n        ftrs = []\n        for block in self.enc_blocks:\n            x = block(x)\n            ftrs.append(x)\n            x = self.pool(x)\n        return ftrs\n\n\nclass Decoder(nn.Module):\n    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n        super().__init__()\n        self.chs         = chs\n        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n        \n    def forward(self, x, encoder_features):\n        for i in range(len(self.chs)-1):\n            x        = self.upconvs[i](x)\n            enc_ftrs = self.crop(encoder_features[i], x)\n            x        = torch.cat([x, enc_ftrs], dim=1)\n            x        = self.dec_blocks[i](x)\n        return x\n    \n    def crop(self, enc_ftrs, x):\n        _, _, H, W = x.shape\n        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n        return enc_ftrs\n\n\nclass UNet(nn.Module):\n    def __init__(self, enc_chs=(3,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64), num_class=1, retain_dim=False, out_sz=(572,572)):\n        super().__init__()\n        self.encoder     = Encoder(enc_chs)\n        self.decoder     = Decoder(dec_chs)\n        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n        self.retain_dim  = retain_dim\n\n    def forward(self, x):\n        enc_ftrs = self.encoder(x)\n        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n        out      = self.head(out)\n        if self.retain_dim:\n            out = F.interpolate(out, out_sz)\n        return out","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=UNet()\nsummary(model,(1,3,572,572))","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Encoder: 1-1                           [1, 64, 568, 568]         --\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-1                   [1, 64, 568, 568]         38,720\n|    └─MaxPool2d: 2-1                    [1, 64, 284, 284]         --\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-2                   [1, 128, 280, 280]        221,440\n|    └─MaxPool2d: 2-2                    [1, 128, 140, 140]        --\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-3                   [1, 256, 136, 136]        885,248\n|    └─MaxPool2d: 2-3                    [1, 256, 68, 68]          --\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-4                   [1, 512, 64, 64]          3,539,968\n|    └─MaxPool2d: 2-4                    [1, 512, 32, 32]          --\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-5                   [1, 1024, 28, 28]         14,157,824\n|    └─MaxPool2d: 2-5                    [1, 1024, 14, 14]         --\n├─Decoder: 1-2                           [1, 64, 388, 388]         --\n|    └─ModuleList: 2                     []                        --\n|    |    └─ConvTranspose2d: 3-6         [1, 512, 56, 56]          2,097,664\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-7                   [1, 512, 52, 52]          7,078,912\n|    └─ModuleList: 2                     []                        --\n|    |    └─ConvTranspose2d: 3-8         [1, 256, 104, 104]        524,544\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-9                   [1, 256, 100, 100]        1,769,984\n|    └─ModuleList: 2                     []                        --\n|    |    └─ConvTranspose2d: 3-10        [1, 128, 200, 200]        131,200\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-11                  [1, 128, 196, 196]        442,624\n|    └─ModuleList: 2                     []                        --\n|    |    └─ConvTranspose2d: 3-12        [1, 64, 392, 392]         32,832\n|    └─ModuleList: 2                     []                        --\n|    |    └─Block: 3-13                  [1, 64, 388, 388]         110,720\n├─Conv2d: 1-3                            [1, 1, 388, 388]          65\n==========================================================================================\nTotal params: 31,031,745\nTrainable params: 31,031,745\nNon-trainable params: 0\nTotal mult-adds (G): 167.75\n==========================================================================================\nInput size (MB): 3.93\nForward/backward pass size (MB): 1073.62\nParams size (MB): 124.13\nEstimated Total Size (MB): 1201.68\n=========================================================================================="},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}